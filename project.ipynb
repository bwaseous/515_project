{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bwa\\anaconda3\\envs\\515_project_gpu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "from project import CreditDefault, PII, SkinCancer, set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit-card default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = CreditDefault()\n",
    "credit.prepare_dataset(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    \"adamw\": (torch.optim.AdamW, {\"lr\": 2e-5}),\n",
    "    \"rmsprop\": (torch.optim.RMSprop, {\"lr\": 2e-5}),\n",
    "    \"adagrad\": (torch.optim.Adagrad, {\"lr\": 2e-5}),\n",
    "}\n",
    "\n",
    "schedulers = {\n",
    "    \"linear\": (torch.optim.lr_scheduler.LinearLR, {\"start_factor\": 0.01, \"end_factor\": 0.0001, \"total_iters\": 2}),\n",
    "    \"cosine\": (torch.optim.lr_scheduler.CosineAnnealing, {\"T_max\": 100, \"eta_min\": 0.01}),\n",
    "    \"polynomial\": (torch.optim.lr_scheduler.PolynomialLR, {\"total_iters\": 100, \"power\": 2})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "|linear, adamw|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.4424096345901489 | accuracy: 0.537\n",
      "\tbatch 2 | loss: 0.4221212863922119 | accuracy: 0.556\n",
      "\tbatch 3 | loss: 0.41576284170150757 | accuracy: 0.563\n",
      "\tbatch 4 | loss: 0.3999929428100586 | accuracy: 0.584\n",
      "\tbatch 5 | loss: 0.3750000596046448 | accuracy: 0.605\n",
      "\tbatch 6 | loss: 0.35946759581565857 | accuracy: 0.618\n",
      "\tbatch 7 | loss: 0.3029974699020386 | accuracy: 0.673\n",
      "\tbatch 8 | loss: 0.3039945960044861 | accuracy: 0.68\n",
      "\tbatch 9 | loss: 0.24527829885482788 | accuracy: 0.725\n",
      "\tbatch 10 | loss: 0.24620354175567627 | accuracy: 0.715\n",
      "\tbatch 11 | loss: 0.2339823693037033 | accuracy: 0.742\n",
      "\tbatch 12 | loss: 0.23700402677059174 | accuracy: 0.746\n",
      "\tbatch 13 | loss: 0.22199484705924988 | accuracy: 0.767\n",
      "\tbatch 14 | loss: 0.2247716784477234 | accuracy: 0.767\n",
      "\tbatch 15 | loss: 0.23900000751018524 | accuracy: 0.755\n",
      "\tbatch 16 | loss: 0.2389996200799942 | accuracy: 0.753\n",
      "\tbatch 17 | loss: 0.2141554355621338 | accuracy: 0.78\n",
      "\tbatch 18 | loss: 0.21477627754211426 | accuracy: 0.781\n",
      "\tbatch 19 | loss: 0.20200000703334808 | accuracy: 0.796\n",
      "\tbatch 20 | loss: 0.23400211334228516 | accuracy: 0.762\n",
      "\tbatch 21 | loss: 0.23200000822544098 | accuracy: 0.767\n",
      "\tbatch 22 | loss: 0.21399931609630585 | accuracy: 0.783\n",
      "\tbatch 23 | loss: 0.244003564119339 | accuracy: 0.754\n",
      "\tbatch 24 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 1 | loss: 0.2290000170469284 | accuracy: 0.769\n",
      "\tbatch 2 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 3 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 4 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 5 | loss: 0.22100001573562622 | accuracy: 0.776\n",
      "\tbatch 6 | loss: 0.21900001168251038 | accuracy: 0.78\n",
      "\tAverage accuracy 0.777\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 2 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 3 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 4 | loss: 0.22200001776218414 | accuracy: 0.775\n",
      "\tbatch 5 | loss: 0.24300001561641693 | accuracy: 0.756\n",
      "\tbatch 6 | loss: 0.20800000429153442 | accuracy: 0.789\n",
      "\tbatch 7 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 8 | loss: 0.22500000894069672 | accuracy: 0.773\n",
      "\tbatch 9 | loss: 0.22800001502037048 | accuracy: 0.771\n",
      "\tbatch 10 | loss: 0.22098027169704437 | accuracy: 0.779\n",
      "\tbatch 11 | loss: 0.23200000822544098 | accuracy: 0.767\n",
      "\tbatch 12 | loss: 0.19700001180171967 | accuracy: 0.802\n",
      "\tbatch 13 | loss: 0.21900001168251038 | accuracy: 0.78\n",
      "\tbatch 14 | loss: 0.2200000137090683 | accuracy: 0.777\n",
      "\tbatch 15 | loss: 0.22020161151885986 | accuracy: 0.779\n",
      "\tbatch 16 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 17 | loss: 0.20600001513957977 | accuracy: 0.793\n",
      "\tbatch 18 | loss: 0.23199857771396637 | accuracy: 0.767\n",
      "\tbatch 19 | loss: 0.24500000476837158 | accuracy: 0.755\n",
      "\tbatch 20 | loss: 0.2144433706998825 | accuracy: 0.783\n",
      "\tbatch 21 | loss: 0.23000000417232513 | accuracy: 0.769\n",
      "\tbatch 22 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 23 | loss: 0.2200000137090683 | accuracy: 0.779\n",
      "\tbatch 24 | loss: 0.23900000751018524 | accuracy: 0.76\n",
      "\tbatch 1 | loss: 0.19200000166893005 | accuracy: 0.808\n",
      "\tbatch 2 | loss: 0.2439984828233719 | accuracy: 0.756\n",
      "\tbatch 3 | loss: 0.23799890279769897 | accuracy: 0.762\n",
      "\tbatch 4 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 5 | loss: 0.22299890220165253 | accuracy: 0.777\n",
      "\tbatch 6 | loss: 0.21900001168251038 | accuracy: 0.78\n",
      "\tAverage accuracy 0.7783333333333333\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 2 | loss: 0.2299986034631729 | accuracy: 0.767\n",
      "\tbatch 3 | loss: 0.23799994587898254 | accuracy: 0.762\n",
      "\tbatch 4 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 5 | loss: 0.22300000488758087 | accuracy: 0.774\n",
      "\tbatch 6 | loss: 0.22500000894069672 | accuracy: 0.774\n",
      "\tbatch 7 | loss: 0.23900000751018524 | accuracy: 0.761\n",
      "\tbatch 8 | loss: 0.2370000183582306 | accuracy: 0.762\n",
      "\tbatch 9 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 10 | loss: 0.20900000631809235 | accuracy: 0.79\n",
      "\tbatch 11 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 12 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 13 | loss: 0.22300000488758087 | accuracy: 0.776\n",
      "\tbatch 14 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 15 | loss: 0.21300001442432404 | accuracy: 0.786\n",
      "\tbatch 16 | loss: 0.22800001502037048 | accuracy: 0.771\n",
      "\tbatch 17 | loss: 0.23900000751018524 | accuracy: 0.761\n",
      "\tbatch 18 | loss: 0.23500001430511475 | accuracy: 0.764\n",
      "\tbatch 19 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 20 | loss: 0.23000000417232513 | accuracy: 0.769\n",
      "\tbatch 21 | loss: 0.23400001227855682 | accuracy: 0.763\n",
      "\tbatch 22 | loss: 0.2150000035762787 | accuracy: 0.782\n",
      "\tbatch 23 | loss: 0.21800000965595245 | accuracy: 0.78\n",
      "\tbatch 24 | loss: 0.21200016140937805 | accuracy: 0.786\n",
      "\tbatch 1 | loss: 0.21900001168251038 | accuracy: 0.78\n",
      "\tbatch 2 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 3 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 4 | loss: 0.22899110615253448 | accuracy: 0.771\n",
      "\tbatch 5 | loss: 0.21499904990196228 | accuracy: 0.785\n",
      "\tbatch 6 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tAverage accuracy 0.7783333333333333\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.22700001299381256 | accuracy: 0.771\n",
      "\tbatch 2 | loss: 0.20100000500679016 | accuracy: 0.799\n",
      "\tbatch 3 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 4 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 5 | loss: 0.22600001096725464 | accuracy: 0.773\n",
      "\tbatch 6 | loss: 0.23600001633167267 | accuracy: 0.763\n",
      "\tbatch 7 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 8 | loss: 0.22899994254112244 | accuracy: 0.768\n",
      "\tbatch 9 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 10 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 11 | loss: 0.22200001776218414 | accuracy: 0.776\n",
      "\tbatch 12 | loss: 0.22800001502037048 | accuracy: 0.769\n",
      "\tbatch 13 | loss: 0.23800000548362732 | accuracy: 0.761\n",
      "\tbatch 14 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 15 | loss: 0.21900001168251038 | accuracy: 0.78\n",
      "\tbatch 16 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 17 | loss: 0.19600000977516174 | accuracy: 0.802\n",
      "\tbatch 18 | loss: 0.22700001299381256 | accuracy: 0.772\n",
      "\tbatch 19 | loss: 0.18700025975704193 | accuracy: 0.81\n",
      "\tbatch 20 | loss: 0.2059977650642395 | accuracy: 0.793\n",
      "\tbatch 21 | loss: 0.2200000137090683 | accuracy: 0.779\n",
      "\tbatch 22 | loss: 0.23500004410743713 | accuracy: 0.763\n",
      "\tbatch 23 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tbatch 24 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 1 | loss: 0.21798498928546906 | accuracy: 0.782\n",
      "\tbatch 2 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 3 | loss: 0.242000013589859 | accuracy: 0.757\n",
      "\tbatch 4 | loss: 0.2249990701675415 | accuracy: 0.775\n",
      "\tbatch 5 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 6 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tAverage accuracy 0.7783333333333333\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.21000000834465027 | accuracy: 0.787\n",
      "\tbatch 2 | loss: 0.22200001776218414 | accuracy: 0.776\n",
      "\tbatch 3 | loss: 0.2110000103712082 | accuracy: 0.786\n",
      "\tbatch 4 | loss: 0.2290000170469284 | accuracy: 0.77\n",
      "\tbatch 5 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 6 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 7 | loss: 0.217997744679451 | accuracy: 0.782\n",
      "\tbatch 8 | loss: 0.22200001776218414 | accuracy: 0.777\n",
      "\tbatch 9 | loss: 0.23000000417232513 | accuracy: 0.768\n",
      "\tbatch 10 | loss: 0.22100001573562622 | accuracy: 0.778\n",
      "\tbatch 11 | loss: 0.19600000977516174 | accuracy: 0.804\n",
      "\tbatch 12 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 13 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 14 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 15 | loss: 0.2330000102519989 | accuracy: 0.766\n",
      "\tbatch 16 | loss: 0.19500000774860382 | accuracy: 0.805\n",
      "\tbatch 17 | loss: 0.2229999452829361 | accuracy: 0.777\n",
      "\tbatch 18 | loss: 0.23100000619888306 | accuracy: 0.768\n",
      "\tbatch 19 | loss: 0.24900004267692566 | accuracy: 0.75\n",
      "\tbatch 20 | loss: 0.24700000882148743 | accuracy: 0.75\n",
      "\tbatch 21 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 22 | loss: 0.21700000762939453 | accuracy: 0.78\n",
      "\tbatch 23 | loss: 0.19700001180171967 | accuracy: 0.803\n",
      "\tbatch 24 | loss: 0.2540002465248108 | accuracy: 0.744\n",
      "\tbatch 1 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 2 | loss: 0.2199990600347519 | accuracy: 0.78\n",
      "\tbatch 3 | loss: 0.21997995674610138 | accuracy: 0.78\n",
      "\tbatch 4 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 5 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 6 | loss: 0.20199817419052124 | accuracy: 0.797\n",
      "\tAverage accuracy 0.7783333333333333\n",
      "-------------------------------------\n",
      "|linear, rmsprop|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.6150901913642883 | accuracy: 0.36\n",
      "\tbatch 2 | loss: 0.24399994313716888 | accuracy: 0.752\n",
      "\tbatch 3 | loss: 0.2539984881877899 | accuracy: 0.741\n",
      "\tbatch 4 | loss: 0.22069096565246582 | accuracy: 0.771\n",
      "\tbatch 5 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 6 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 7 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 8 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 9 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 10 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 11 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 12 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 13 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 14 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 15 | loss: 0.1990000158548355 | accuracy: 0.801\n",
      "\tbatch 16 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 17 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 18 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 19 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 20 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 21 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 22 | loss: 0.1990000158548355 | accuracy: 0.801\n",
      "\tbatch 23 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 24 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 1 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 2 | loss: 0.24300001561641693 | accuracy: 0.757\n",
      "\tbatch 3 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 4 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 5 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 6 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 2 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 3 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 4 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 5 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 6 | loss: 0.25 | accuracy: 0.75\n",
      "\tbatch 7 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 8 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 9 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 10 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 11 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 12 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 13 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 14 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 15 | loss: 0.19700001180171967 | accuracy: 0.803\n",
      "\tbatch 16 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 17 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 18 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 19 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 20 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 21 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 22 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 23 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 24 | loss: 0.21700000762939453 | accuracy: 0.782\n",
      "\tbatch 1 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 2 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 3 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 4 | loss: 0.23900000751018524 | accuracy: 0.761\n",
      "\tbatch 5 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 6 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 2 | loss: 0.20499996840953827 | accuracy: 0.795\n",
      "\tbatch 3 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 4 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 5 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 6 | loss: 0.24400001764297485 | accuracy: 0.756\n",
      "\tbatch 7 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 8 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 9 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 10 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 11 | loss: 0.25 | accuracy: 0.75\n",
      "\tbatch 12 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 13 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 14 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 15 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 16 | loss: 0.20900000631809235 | accuracy: 0.79\n",
      "\tbatch 17 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 18 | loss: 0.25300002098083496 | accuracy: 0.747\n",
      "\tbatch 19 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 20 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 21 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 22 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 23 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 24 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 1 | loss: 0.19300000369548798 | accuracy: 0.807\n",
      "\tbatch 2 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 3 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 4 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 5 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 6 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.21199969947338104 | accuracy: 0.788\n",
      "\tbatch 2 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 3 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 4 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 5 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 6 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 7 | loss: 0.24300001561641693 | accuracy: 0.757\n",
      "\tbatch 8 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 9 | loss: 0.2460000067949295 | accuracy: 0.753\n",
      "\tbatch 10 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 11 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 12 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 13 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 14 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 15 | loss: 0.18700000643730164 | accuracy: 0.813\n",
      "\tbatch 16 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 17 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 18 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 19 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 20 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 21 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 22 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 23 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 24 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 1 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 2 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 3 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 4 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 5 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 6 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 2 | loss: 0.19600000977516174 | accuracy: 0.803\n",
      "\tbatch 3 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 4 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 5 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 6 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 7 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 8 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 9 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 10 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 11 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 12 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 13 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 14 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 15 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 16 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 17 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 18 | loss: 0.24598655104637146 | accuracy: 0.754\n",
      "\tbatch 19 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 20 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 21 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 22 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 23 | loss: 0.2410000115633011 | accuracy: 0.759\n",
      "\tbatch 24 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 1 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 2 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 3 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 4 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 5 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 6 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "-------------------------------------\n",
      "|linear, adagrad|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.2150000035762787 | accuracy: 0.782\n",
      "\tbatch 2 | loss: 0.20500001311302185 | accuracy: 0.793\n",
      "\tbatch 3 | loss: 0.21799997985363007 | accuracy: 0.779\n",
      "\tbatch 4 | loss: 0.21899960935115814 | accuracy: 0.777\n",
      "\tbatch 5 | loss: 0.242000013589859 | accuracy: 0.748\n",
      "\tbatch 6 | loss: 0.23999832570552826 | accuracy: 0.757\n",
      "\tbatch 7 | loss: 0.23800000548362732 | accuracy: 0.758\n",
      "\tbatch 8 | loss: 0.2190966010093689 | accuracy: 0.776\n",
      "\tbatch 9 | loss: 0.2099999189376831 | accuracy: 0.788\n",
      "\tbatch 10 | loss: 0.20200000703334808 | accuracy: 0.796\n",
      "\tbatch 11 | loss: 0.2160000056028366 | accuracy: 0.781\n",
      "\tbatch 12 | loss: 0.22600001096725464 | accuracy: 0.773\n",
      "\tbatch 13 | loss: 0.20000000298023224 | accuracy: 0.797\n",
      "\tbatch 14 | loss: 0.2160000056028366 | accuracy: 0.779\n",
      "\tbatch 15 | loss: 0.2477458417415619 | accuracy: 0.749\n",
      "\tbatch 16 | loss: 0.21399623155593872 | accuracy: 0.785\n",
      "\tbatch 17 | loss: 0.22700001299381256 | accuracy: 0.771\n",
      "\tbatch 18 | loss: 0.2330000102519989 | accuracy: 0.761\n",
      "\tbatch 19 | loss: 0.22500000894069672 | accuracy: 0.772\n",
      "\tbatch 20 | loss: 0.23100002110004425 | accuracy: 0.763\n",
      "\tbatch 21 | loss: 0.23169036209583282 | accuracy: 0.766\n",
      "\tbatch 22 | loss: 0.19500000774860382 | accuracy: 0.803\n",
      "\tbatch 23 | loss: 0.2290000170469284 | accuracy: 0.767\n",
      "\tbatch 24 | loss: 0.26200026273727417 | accuracy: 0.734\n",
      "\tbatch 1 | loss: 0.23200000822544098 | accuracy: 0.764\n",
      "\tbatch 2 | loss: 0.22000351548194885 | accuracy: 0.776\n",
      "\tbatch 3 | loss: 0.21000000834465027 | accuracy: 0.789\n",
      "\tbatch 4 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 5 | loss: 0.22300000488758087 | accuracy: 0.775\n",
      "\tbatch 6 | loss: 0.23800000548362732 | accuracy: 0.759\n",
      "\tAverage accuracy 0.7771666666666667\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.21900001168251038 | accuracy: 0.779\n",
      "\tbatch 2 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 3 | loss: 0.2120000123977661 | accuracy: 0.784\n",
      "\tbatch 4 | loss: 0.22700001299381256 | accuracy: 0.771\n",
      "\tbatch 5 | loss: 0.21000000834465027 | accuracy: 0.786\n",
      "\tbatch 6 | loss: 0.2300039827823639 | accuracy: 0.767\n",
      "\tbatch 7 | loss: 0.22500000894069672 | accuracy: 0.772\n",
      "\tbatch 8 | loss: 0.22700001299381256 | accuracy: 0.772\n",
      "\tbatch 9 | loss: 0.22100001573562622 | accuracy: 0.775\n",
      "\tbatch 10 | loss: 0.21000000834465027 | accuracy: 0.787\n",
      "\tbatch 11 | loss: 0.22100019454956055 | accuracy: 0.776\n",
      "\tbatch 12 | loss: 0.23800000548362732 | accuracy: 0.761\n",
      "\tbatch 13 | loss: 0.21700000762939453 | accuracy: 0.779\n",
      "\tbatch 14 | loss: 0.2240000069141388 | accuracy: 0.774\n",
      "\tbatch 15 | loss: 0.22300000488758087 | accuracy: 0.772\n",
      "\tbatch 16 | loss: 0.22500000894069672 | accuracy: 0.773\n",
      "\tbatch 17 | loss: 0.21999989449977875 | accuracy: 0.778\n",
      "\tbatch 18 | loss: 0.22200001776218414 | accuracy: 0.774\n",
      "\tbatch 19 | loss: 0.2120000123977661 | accuracy: 0.787\n",
      "\tbatch 20 | loss: 0.23600001633167267 | accuracy: 0.759\n",
      "\tbatch 21 | loss: 0.23000000417232513 | accuracy: 0.766\n",
      "\tbatch 22 | loss: 0.22174499928951263 | accuracy: 0.771\n",
      "\tbatch 23 | loss: 0.22100001573562622 | accuracy: 0.776\n",
      "\tbatch 24 | loss: 0.21800000965595245 | accuracy: 0.778\n",
      "\tbatch 1 | loss: 0.21545447409152985 | accuracy: 0.783\n",
      "\tbatch 2 | loss: 0.21699997782707214 | accuracy: 0.781\n",
      "\tbatch 3 | loss: 0.21800008416175842 | accuracy: 0.778\n",
      "\tbatch 4 | loss: 0.22500000894069672 | accuracy: 0.773\n",
      "\tbatch 5 | loss: 0.24900001287460327 | accuracy: 0.75\n",
      "\tbatch 6 | loss: 0.1990000158548355 | accuracy: 0.796\n",
      "\tAverage accuracy 0.7768333333333334\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.22200001776218414 | accuracy: 0.777\n",
      "\tbatch 2 | loss: 0.21200017631053925 | accuracy: 0.784\n",
      "\tbatch 3 | loss: 0.2150000035762787 | accuracy: 0.783\n",
      "\tbatch 4 | loss: 0.2110000103712082 | accuracy: 0.786\n",
      "\tbatch 5 | loss: 0.22600001096725464 | accuracy: 0.773\n",
      "\tbatch 6 | loss: 0.18800033628940582 | accuracy: 0.803\n",
      "\tbatch 7 | loss: 0.22600001096725464 | accuracy: 0.772\n",
      "\tbatch 8 | loss: 0.23704905807971954 | accuracy: 0.759\n",
      "\tbatch 9 | loss: 0.20400001108646393 | accuracy: 0.791\n",
      "\tbatch 10 | loss: 0.20899976789951324 | accuracy: 0.787\n",
      "\tbatch 11 | loss: 0.22700001299381256 | accuracy: 0.769\n",
      "\tbatch 12 | loss: 0.23400001227855682 | accuracy: 0.764\n",
      "\tbatch 13 | loss: 0.23400001227855682 | accuracy: 0.764\n",
      "\tbatch 14 | loss: 0.22600001096725464 | accuracy: 0.771\n",
      "\tbatch 15 | loss: 0.22399862110614777 | accuracy: 0.772\n",
      "\tbatch 16 | loss: 0.2048245519399643 | accuracy: 0.793\n",
      "\tbatch 17 | loss: 0.22100143134593964 | accuracy: 0.776\n",
      "\tbatch 18 | loss: 0.2290000170469284 | accuracy: 0.77\n",
      "\tbatch 19 | loss: 0.21217888593673706 | accuracy: 0.785\n",
      "\tbatch 20 | loss: 0.21700000762939453 | accuracy: 0.781\n",
      "\tbatch 21 | loss: 0.2370000183582306 | accuracy: 0.76\n",
      "\tbatch 22 | loss: 0.2380134016275406 | accuracy: 0.757\n",
      "\tbatch 23 | loss: 0.24400001764297485 | accuracy: 0.751\n",
      "\tbatch 24 | loss: 0.24400001764297485 | accuracy: 0.753\n",
      "\tbatch 1 | loss: 0.21899515390396118 | accuracy: 0.778\n",
      "\tbatch 2 | loss: 0.23400001227855682 | accuracy: 0.763\n",
      "\tbatch 3 | loss: 0.2335238754749298 | accuracy: 0.763\n",
      "\tbatch 4 | loss: 0.1940000057220459 | accuracy: 0.803\n",
      "\tbatch 5 | loss: 0.2109999805688858 | accuracy: 0.787\n",
      "\tbatch 6 | loss: 0.23200000822544098 | accuracy: 0.767\n",
      "\tAverage accuracy 0.7768333333333333\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.22300000488758087 | accuracy: 0.774\n",
      "\tbatch 2 | loss: 0.22200001776218414 | accuracy: 0.776\n",
      "\tbatch 3 | loss: 0.21900001168251038 | accuracy: 0.777\n",
      "\tbatch 4 | loss: 0.21800000965595245 | accuracy: 0.78\n",
      "\tbatch 5 | loss: 0.22000131011009216 | accuracy: 0.778\n",
      "\tbatch 6 | loss: 0.24300001561641693 | accuracy: 0.753\n",
      "\tbatch 7 | loss: 0.23200000822544098 | accuracy: 0.764\n",
      "\tbatch 8 | loss: 0.22500064969062805 | accuracy: 0.774\n",
      "\tbatch 9 | loss: 0.207015722990036 | accuracy: 0.789\n",
      "\tbatch 10 | loss: 0.22016790509223938 | accuracy: 0.776\n",
      "\tbatch 11 | loss: 0.23400001227855682 | accuracy: 0.761\n",
      "\tbatch 12 | loss: 0.21501126885414124 | accuracy: 0.779\n",
      "\tbatch 13 | loss: 0.24500000476837158 | accuracy: 0.751\n",
      "\tbatch 14 | loss: 0.2060001939535141 | accuracy: 0.789\n",
      "\tbatch 15 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 16 | loss: 0.20599931478500366 | accuracy: 0.789\n",
      "\tbatch 17 | loss: 0.2229989469051361 | accuracy: 0.775\n",
      "\tbatch 18 | loss: 0.24300001561641693 | accuracy: 0.755\n",
      "\tbatch 19 | loss: 0.2410000115633011 | accuracy: 0.756\n",
      "\tbatch 20 | loss: 0.22300000488758087 | accuracy: 0.775\n",
      "\tbatch 21 | loss: 0.2120000123977661 | accuracy: 0.785\n",
      "\tbatch 22 | loss: 0.19479745626449585 | accuracy: 0.8\n",
      "\tbatch 23 | loss: 0.23400001227855682 | accuracy: 0.764\n",
      "\tbatch 24 | loss: 0.22100001573562622 | accuracy: 0.776\n",
      "\tbatch 1 | loss: 0.22099420428276062 | accuracy: 0.777\n",
      "\tbatch 2 | loss: 0.21400001645088196 | accuracy: 0.779\n",
      "\tbatch 3 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 4 | loss: 0.22100001573562622 | accuracy: 0.778\n",
      "\tbatch 5 | loss: 0.22600001096725464 | accuracy: 0.773\n",
      "\tbatch 6 | loss: 0.2065729796886444 | accuracy: 0.789\n",
      "\tAverage accuracy 0.7768333333333334\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.23500001430511475 | accuracy: 0.76\n",
      "\tbatch 2 | loss: 0.21300001442432404 | accuracy: 0.782\n",
      "\tbatch 3 | loss: 0.22800131142139435 | accuracy: 0.77\n",
      "\tbatch 4 | loss: 0.21700000762939453 | accuracy: 0.776\n",
      "\tbatch 5 | loss: 0.23499898612499237 | accuracy: 0.763\n",
      "\tbatch 6 | loss: 0.22100001573562622 | accuracy: 0.776\n",
      "\tbatch 7 | loss: 0.19600000977516174 | accuracy: 0.802\n",
      "\tbatch 8 | loss: 0.23378831148147583 | accuracy: 0.761\n",
      "\tbatch 9 | loss: 0.2290000170469284 | accuracy: 0.77\n",
      "\tbatch 10 | loss: 0.21900001168251038 | accuracy: 0.779\n",
      "\tbatch 11 | loss: 0.23000000417232513 | accuracy: 0.766\n",
      "\tbatch 12 | loss: 0.22315575182437897 | accuracy: 0.773\n",
      "\tbatch 13 | loss: 0.21200016140937805 | accuracy: 0.787\n",
      "\tbatch 14 | loss: 0.23600001633167267 | accuracy: 0.761\n",
      "\tbatch 15 | loss: 0.21200595796108246 | accuracy: 0.783\n",
      "\tbatch 16 | loss: 0.2410000115633011 | accuracy: 0.757\n",
      "\tbatch 17 | loss: 0.2290000170469284 | accuracy: 0.77\n",
      "\tbatch 18 | loss: 0.2089984118938446 | accuracy: 0.789\n",
      "\tbatch 19 | loss: 0.21400001645088196 | accuracy: 0.78\n",
      "\tbatch 20 | loss: 0.2370000183582306 | accuracy: 0.758\n",
      "\tbatch 21 | loss: 0.21400001645088196 | accuracy: 0.784\n",
      "\tbatch 22 | loss: 0.23000000417232513 | accuracy: 0.769\n",
      "\tbatch 23 | loss: 0.2260008603334427 | accuracy: 0.768\n",
      "\tbatch 24 | loss: 0.20200000703334808 | accuracy: 0.796\n",
      "\tbatch 1 | loss: 0.2329932004213333 | accuracy: 0.763\n",
      "\tbatch 2 | loss: 0.21661323308944702 | accuracy: 0.779\n",
      "\tbatch 3 | loss: 0.2160000056028366 | accuracy: 0.782\n",
      "\tbatch 4 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 5 | loss: 0.2070000171661377 | accuracy: 0.79\n",
      "\tbatch 6 | loss: 0.2290000170469284 | accuracy: 0.769\n",
      "\tAverage accuracy 0.7768333333333333\n",
      "-------------------------------------\n",
      "|cos_warm, adamw|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.784000039100647 | accuracy: 0.216\n",
      "\tbatch 2 | loss: 0.7660000324249268 | accuracy: 0.234\n",
      "\tbatch 3 | loss: 0.7750000357627869 | accuracy: 0.225\n",
      "\tbatch 4 | loss: 0.7790000438690186 | accuracy: 0.221\n",
      "\tbatch 5 | loss: 0.7660000324249268 | accuracy: 0.234\n",
      "\tbatch 6 | loss: 0.7850000262260437 | accuracy: 0.215\n",
      "\tbatch 7 | loss: 0.7780000567436218 | accuracy: 0.222\n",
      "\tbatch 8 | loss: 0.7770000100135803 | accuracy: 0.223\n",
      "\tbatch 9 | loss: 0.781000018119812 | accuracy: 0.219\n",
      "\tbatch 10 | loss: 0.7880000472068787 | accuracy: 0.212\n",
      "\tbatch 11 | loss: 0.7600000500679016 | accuracy: 0.24\n",
      "\tbatch 12 | loss: 0.7760000228881836 | accuracy: 0.224\n",
      "\tbatch 13 | loss: 0.7740000486373901 | accuracy: 0.226\n",
      "\tbatch 14 | loss: 0.7880000472068787 | accuracy: 0.212\n",
      "\tbatch 15 | loss: 0.784000039100647 | accuracy: 0.216\n",
      "\tbatch 16 | loss: 0.7660000324249268 | accuracy: 0.234\n",
      "\tbatch 17 | loss: 0.7800000309944153 | accuracy: 0.22\n",
      "\tbatch 18 | loss: 0.7800000309944153 | accuracy: 0.22\n",
      "\tbatch 19 | loss: 0.7970000505447388 | accuracy: 0.203\n",
      "\tbatch 20 | loss: 0.7940000295639038 | accuracy: 0.205\n",
      "\tbatch 21 | loss: 0.7540000081062317 | accuracy: 0.246\n",
      "\tbatch 22 | loss: 0.7970000505447388 | accuracy: 0.202\n",
      "\tbatch 23 | loss: 0.7610000371932983 | accuracy: 0.239\n",
      "\tbatch 24 | loss: 0.7790000438690186 | accuracy: 0.221\n",
      "\tbatch 1 | loss: 0.8060000538825989 | accuracy: 0.194\n",
      "\tbatch 2 | loss: 0.762999415397644 | accuracy: 0.237\n",
      "\tbatch 3 | loss: 0.778184711933136 | accuracy: 0.22\n",
      "\tbatch 4 | loss: 0.7890000343322754 | accuracy: 0.211\n",
      "\tbatch 5 | loss: 0.7640000581741333 | accuracy: 0.233\n",
      "\tbatch 6 | loss: 0.7700000405311584 | accuracy: 0.229\n",
      "\tAverage accuracy 0.22066666666666668\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.7779709696769714 | accuracy: 0.222\n",
      "\tbatch 2 | loss: 0.1990000158548355 | accuracy: 0.801\n",
      "\tbatch 3 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 4 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 5 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 6 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 7 | loss: 0.2410000115633011 | accuracy: 0.759\n",
      "\tbatch 8 | loss: 0.19600000977516174 | accuracy: 0.804\n",
      "\tbatch 9 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 10 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 11 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 12 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 13 | loss: 0.26200002431869507 | accuracy: 0.738\n",
      "\tbatch 14 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 15 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 16 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 17 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 18 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 19 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 20 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 21 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 22 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 23 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 24 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 1 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 2 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 3 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 4 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 5 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 6 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 2 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 3 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 4 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 5 | loss: 0.24300001561641693 | accuracy: 0.757\n",
      "\tbatch 6 | loss: 0.20100000500679016 | accuracy: 0.799\n",
      "\tbatch 7 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 8 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 9 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 10 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 11 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 12 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 13 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 14 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 15 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 16 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 17 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 18 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 19 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 20 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 21 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 22 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 23 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 24 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 1 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 2 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 3 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 4 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 5 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 6 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 2 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 3 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 4 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 5 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 6 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 7 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 8 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 9 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 10 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 11 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 12 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 13 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 14 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 15 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 16 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tbatch 17 | loss: 0.19600000977516174 | accuracy: 0.804\n",
      "\tbatch 18 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 19 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 20 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 21 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 22 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 23 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 24 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 1 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 2 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 3 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 4 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 5 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 6 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 2 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 3 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 4 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 5 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 6 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 7 | loss: 0.25 | accuracy: 0.75\n",
      "\tbatch 8 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 9 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 10 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 11 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 12 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 13 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 14 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 15 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 16 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 17 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 18 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 19 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 20 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 21 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 22 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 23 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 24 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 1 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 2 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 3 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 4 | loss: 0.23900000751018524 | accuracy: 0.761\n",
      "\tbatch 5 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 6 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "-------------------------------------\n",
      "|cos_warm, rmsprop|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.5370003581047058 | accuracy: 0.455\n",
      "\tbatch 2 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 3 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 4 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 5 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 6 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 7 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 8 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tbatch 9 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 10 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 11 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 12 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 13 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 14 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 15 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 16 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 17 | loss: 0.1980000138282776 | accuracy: 0.802\n",
      "\tbatch 18 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 19 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 20 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 21 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 22 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 23 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 24 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 1 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tbatch 2 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 3 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 4 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 5 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 6 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 2 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 3 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 4 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 5 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 6 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 7 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 8 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 9 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 10 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 11 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 12 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 13 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 14 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 15 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 16 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 17 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 18 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 19 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 20 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 21 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 22 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 23 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 24 | loss: 0.24500000476837158 | accuracy: 0.755\n",
      "\tbatch 1 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 2 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 3 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 4 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 5 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 6 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tAverage accuracy 0.7811666666666669\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 2 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 3 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 4 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 5 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 6 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 7 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 8 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 9 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 10 | loss: 0.25 | accuracy: 0.75\n",
      "\tbatch 11 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 12 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 13 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 14 | loss: 0.19700001180171967 | accuracy: 0.803\n",
      "\tbatch 15 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 16 | loss: 0.19300000369548798 | accuracy: 0.807\n",
      "\tbatch 17 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 18 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 19 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 20 | loss: 0.24700000882148743 | accuracy: 0.753\n",
      "\tbatch 21 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tbatch 22 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 23 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 24 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 1 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 2 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 3 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 4 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 5 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 6 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tAverage accuracy 0.7811666666666666\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 2 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 3 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 4 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 5 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 6 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 7 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 8 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 9 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 10 | loss: 0.1980000138282776 | accuracy: 0.802\n",
      "\tbatch 11 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 12 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 13 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 14 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 15 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 16 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 17 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 18 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 19 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 20 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 21 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 22 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 23 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 24 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 1 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 2 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 3 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 4 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 5 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 6 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tAverage accuracy 0.7811666666666666\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 2 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 3 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 4 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 5 | loss: 0.1860000044107437 | accuracy: 0.814\n",
      "\tbatch 6 | loss: 0.24700000882148743 | accuracy: 0.753\n",
      "\tbatch 7 | loss: 0.19100001454353333 | accuracy: 0.809\n",
      "\tbatch 8 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 9 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 10 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 11 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 12 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 13 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 14 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 15 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 16 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 17 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 18 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 19 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 20 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 21 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 22 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 23 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 24 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 1 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 2 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 3 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 4 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 5 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 6 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "-------------------------------------\n",
      "|cos_warm, adagrad|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 2 | loss: 0.24900001287460327 | accuracy: 0.751\n",
      "\tbatch 3 | loss: 0.18800000846385956 | accuracy: 0.812\n",
      "\tbatch 4 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 5 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 6 | loss: 0.24300001561641693 | accuracy: 0.757\n",
      "\tbatch 7 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 8 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 9 | loss: 0.19499260187149048 | accuracy: 0.804\n",
      "\tbatch 10 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 11 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 12 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 13 | loss: 0.25 | accuracy: 0.75\n",
      "\tbatch 14 | loss: 0.1900000125169754 | accuracy: 0.81\n",
      "\tbatch 15 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 16 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 17 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 18 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 19 | loss: 0.24800001084804535 | accuracy: 0.752\n",
      "\tbatch 20 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 21 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 22 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 23 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 24 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 1 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 2 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 3 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 4 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 5 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 6 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 2 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 3 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 4 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 5 | loss: 0.2410000115633011 | accuracy: 0.759\n",
      "\tbatch 6 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 7 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 8 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 9 | loss: 0.24300001561641693 | accuracy: 0.757\n",
      "\tbatch 10 | loss: 0.18900001049041748 | accuracy: 0.811\n",
      "\tbatch 11 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 12 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 13 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 14 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 15 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 16 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 17 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 18 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 19 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 20 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 21 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 22 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 23 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 24 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 1 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 2 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 3 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 4 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 5 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 6 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.19600000977516174 | accuracy: 0.804\n",
      "\tbatch 2 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 3 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 4 | loss: 0.2410000115633011 | accuracy: 0.759\n",
      "\tbatch 5 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 6 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 7 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tbatch 8 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 9 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 10 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 11 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 12 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 13 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 14 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 15 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tbatch 16 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 17 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 18 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 19 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 20 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 21 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 22 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 23 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 24 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 1 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 2 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 3 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 4 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 5 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 6 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tAverage accuracy 0.7811666666666666\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 2 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 3 | loss: 0.2410000115633011 | accuracy: 0.759\n",
      "\tbatch 4 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 5 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 6 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 7 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 8 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 9 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 10 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 11 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 12 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 13 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 14 | loss: 0.20100000500679016 | accuracy: 0.799\n",
      "\tbatch 15 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 16 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 17 | loss: 0.25200000405311584 | accuracy: 0.748\n",
      "\tbatch 18 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 19 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 20 | loss: 0.24400001764297485 | accuracy: 0.756\n",
      "\tbatch 21 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 22 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 23 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 24 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 1 | loss: 0.23900000751018524 | accuracy: 0.761\n",
      "\tbatch 2 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 3 | loss: 0.19600000977516174 | accuracy: 0.804\n",
      "\tbatch 4 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 5 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 6 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tAverage accuracy 0.7811666666666666\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 2 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 3 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 4 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 5 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 6 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 7 | loss: 0.24800001084804535 | accuracy: 0.752\n",
      "\tbatch 8 | loss: 0.1980000138282776 | accuracy: 0.802\n",
      "\tbatch 9 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 10 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 11 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 12 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 13 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tbatch 14 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 15 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 16 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 17 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 18 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 19 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 20 | loss: 0.24900001287460327 | accuracy: 0.751\n",
      "\tbatch 21 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 22 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 23 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 24 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 1 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 2 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 3 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 4 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 5 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 6 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "-------------------------------------\n",
      "|plateau, adamw|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.7509990334510803 | accuracy: 0.238\n",
      "\tbatch 2 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 3 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 4 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 5 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 6 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 7 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 8 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 9 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 10 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 11 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 12 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 13 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 14 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 15 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 16 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 17 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 18 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 19 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 20 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 21 | loss: 0.24400001764297485 | accuracy: 0.756\n",
      "\tbatch 22 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 23 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 24 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 1 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 2 | loss: 0.19600000977516174 | accuracy: 0.804\n",
      "\tbatch 3 | loss: 0.24700000882148743 | accuracy: 0.753\n",
      "\tbatch 4 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 5 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 6 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 2 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 3 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 4 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 5 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 6 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 7 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 8 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 9 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 10 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 11 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 12 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 13 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 14 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 15 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 16 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tbatch 17 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 18 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 19 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 20 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 21 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 22 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 23 | loss: 0.20100000500679016 | accuracy: 0.799\n",
      "\tbatch 24 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 1 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 2 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 3 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 4 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 5 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 6 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 2 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 3 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 4 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 5 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 6 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 7 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 8 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 9 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 10 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 11 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 12 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 13 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 14 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 15 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 16 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 17 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 18 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 19 | loss: 0.24500000476837158 | accuracy: 0.755\n",
      "\tbatch 20 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 21 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 22 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 23 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 24 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 1 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 2 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 3 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 4 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 5 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 6 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.2410000115633011 | accuracy: 0.759\n",
      "\tbatch 2 | loss: 0.1980000138282776 | accuracy: 0.802\n",
      "\tbatch 3 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 4 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 5 | loss: 0.24300001561641693 | accuracy: 0.757\n",
      "\tbatch 6 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 7 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 8 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 9 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 10 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 11 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 12 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 13 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 14 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 15 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 16 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 17 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 18 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 19 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 20 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 21 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 22 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 23 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 24 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 1 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 2 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 3 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 4 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 5 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tbatch 6 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tAverage accuracy 0.7811666666666666\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.1980000138282776 | accuracy: 0.802\n",
      "\tbatch 2 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 3 | loss: 0.2540000081062317 | accuracy: 0.746\n",
      "\tbatch 4 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 5 | loss: 0.1980000138282776 | accuracy: 0.802\n",
      "\tbatch 6 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 7 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 8 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 9 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 10 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 11 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 12 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 13 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 14 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 15 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tbatch 16 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 17 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tbatch 18 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 19 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 20 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 21 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 22 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 23 | loss: 0.1980000138282776 | accuracy: 0.802\n",
      "\tbatch 24 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 1 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 2 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 3 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 4 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 5 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 6 | loss: 0.1980000138282776 | accuracy: 0.802\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "-------------------------------------\n",
      "|plateau, rmsprop|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.6025660634040833 | accuracy: 0.368\n",
      "\tbatch 2 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tbatch 3 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 4 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 5 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 6 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 7 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 8 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 9 | loss: 0.26200002431869507 | accuracy: 0.738\n",
      "\tbatch 10 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 11 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 12 | loss: 0.24800001084804535 | accuracy: 0.752\n",
      "\tbatch 13 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 14 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 15 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 16 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 17 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 18 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 19 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 20 | loss: 0.19300000369548798 | accuracy: 0.807\n",
      "\tbatch 21 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 22 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 23 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 24 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 1 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 2 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 3 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 4 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 5 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 6 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 2 | loss: 0.25300002098083496 | accuracy: 0.747\n",
      "\tbatch 3 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 4 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 5 | loss: 0.2410000115633011 | accuracy: 0.759\n",
      "\tbatch 6 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 7 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 8 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 9 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 10 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 11 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 12 | loss: 0.20100000500679016 | accuracy: 0.799\n",
      "\tbatch 13 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 14 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 15 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 16 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 17 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 18 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 19 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 20 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 21 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 22 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 23 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 24 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 1 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 2 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 3 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 4 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 5 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 6 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.1850000023841858 | accuracy: 0.815\n",
      "\tbatch 2 | loss: 0.2540000081062317 | accuracy: 0.746\n",
      "\tbatch 3 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 4 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 5 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 6 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 7 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 8 | loss: 0.26500001549720764 | accuracy: 0.735\n",
      "\tbatch 9 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 10 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 11 | loss: 0.23900000751018524 | accuracy: 0.761\n",
      "\tbatch 12 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 13 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 14 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 15 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 16 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 17 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 18 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 19 | loss: 0.1990000158548355 | accuracy: 0.801\n",
      "\tbatch 20 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 21 | loss: 0.25200000405311584 | accuracy: 0.748\n",
      "\tbatch 22 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 23 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 24 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 1 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 2 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 3 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 4 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 5 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 6 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tAverage accuracy 0.7811666666666666\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 2 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 3 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 4 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 5 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 6 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 7 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 8 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 9 | loss: 0.19300000369548798 | accuracy: 0.807\n",
      "\tbatch 10 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 11 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 12 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 13 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 14 | loss: 0.1990000158548355 | accuracy: 0.801\n",
      "\tbatch 15 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 16 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 17 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 18 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 19 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 20 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 21 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 22 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 23 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 24 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 1 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 2 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 3 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 4 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 5 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 6 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tAverage accuracy 0.7811666666666666\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 2 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 3 | loss: 0.2670000195503235 | accuracy: 0.733\n",
      "\tbatch 4 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 5 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 6 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 7 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 8 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 9 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 10 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 11 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 12 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 13 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 14 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 15 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 16 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 17 | loss: 0.1990000158548355 | accuracy: 0.801\n",
      "\tbatch 18 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 19 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 20 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 21 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 22 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 23 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tbatch 24 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 1 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 2 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 3 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 4 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 5 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 6 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "-------------------------------------\n",
      "|plateau, adagrad|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.7710000276565552 | accuracy: 0.229\n",
      "\tbatch 2 | loss: 0.7450000643730164 | accuracy: 0.255\n",
      "\tbatch 3 | loss: 0.7930000424385071 | accuracy: 0.207\n",
      "\tbatch 4 | loss: 0.7780000567436218 | accuracy: 0.221\n",
      "\tbatch 5 | loss: 0.7600000500679016 | accuracy: 0.24\n",
      "\tbatch 6 | loss: 0.7880000472068787 | accuracy: 0.212\n",
      "\tbatch 7 | loss: 0.7830000519752502 | accuracy: 0.217\n",
      "\tbatch 8 | loss: 0.7600000500679016 | accuracy: 0.239\n",
      "\tbatch 9 | loss: 0.7830000519752502 | accuracy: 0.217\n",
      "\tbatch 10 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 11 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 12 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 13 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 14 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 15 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 16 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 17 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 18 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 19 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 20 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 21 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 22 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 23 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 24 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 1 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 2 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 3 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 4 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 5 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 6 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tAverage accuracy 0.7811666666666666\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 2 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 3 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 4 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tbatch 5 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 6 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 7 | loss: 0.23900000751018524 | accuracy: 0.761\n",
      "\tbatch 8 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 9 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 10 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 11 | loss: 0.20100000500679016 | accuracy: 0.799\n",
      "\tbatch 12 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 13 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 14 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 15 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 16 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 17 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 18 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 19 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 20 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 21 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 22 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 23 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 24 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 1 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 2 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 3 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 4 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 5 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 6 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.25200000405311584 | accuracy: 0.748\n",
      "\tbatch 2 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 3 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 4 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 5 | loss: 0.24900001287460327 | accuracy: 0.751\n",
      "\tbatch 6 | loss: 0.24700000882148743 | accuracy: 0.753\n",
      "\tbatch 7 | loss: 0.1940000057220459 | accuracy: 0.806\n",
      "\tbatch 8 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 9 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 10 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 11 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 12 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 13 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 14 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 15 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 16 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 17 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 18 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 19 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 20 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 21 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 22 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 23 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 24 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 1 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 2 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 3 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 4 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 5 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 6 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 2 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 3 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 4 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 5 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 6 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 7 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 8 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 9 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 10 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 11 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 12 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 13 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 14 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 15 | loss: 0.19300000369548798 | accuracy: 0.807\n",
      "\tbatch 16 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 17 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 18 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 19 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tbatch 20 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 21 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 22 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 23 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 24 | loss: 0.24500000476837158 | accuracy: 0.755\n",
      "\tbatch 1 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 2 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 3 | loss: 0.18900001049041748 | accuracy: 0.811\n",
      "\tbatch 4 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 5 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 6 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 2 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 3 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 4 | loss: 0.24900001287460327 | accuracy: 0.751\n",
      "\tbatch 5 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 6 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 7 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 8 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 9 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 10 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 11 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 12 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 13 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 14 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 15 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 16 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 17 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 18 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 19 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 20 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 21 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 22 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 23 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 24 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 1 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 2 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 3 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 4 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 5 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 6 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tAverage accuracy 0.7811666666666667\n"
     ]
    }
   ],
   "source": [
    "df = credit.train(\n",
    "    result_csv = \"test.csv\", \n",
    "    optimizers = optimizers,\n",
    "    schedulers = schedulers,\n",
    "    epochs = 5,\n",
    "    batch_size = 1000,\n",
    "    device = \"cuda\",\n",
    "    loss_func = torch.nn.MSELoss\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"distilbert/distilroberta-base\"\n",
    "\n",
    "pii = PII()\n",
    "pii.load_tokenizer(model_path)\n",
    "pii.prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    #\"adamw\": (torch.optim.AdamW, {\"lr\": 2e-4}),\n",
    "    #\"rmsprop\": (torch.optim.RMSprop, {\"lr\": 2e-4, \"momentum\": 0}),\n",
    "    \"adagrad\": (torch.optim.Adagrad, {\"lr\": 3e-5}),\n",
    "}\n",
    "\n",
    "schedulers = {\n",
    "    \"linear\": {\"num_warmup_steps\": 0},\n",
    "    \"cosine\": {\"num_warmup_steps\": 0},\n",
    "    \"polynomial\": {\"num_warmup_steps\": 0, \"power\": 2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Optimizer: adagrad | Scheduler: linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27008575201034546, 'eval_precision': 0.647475015477138, 'eval_recall': 0.6914431431809596, 'eval_f1': 0.6687371546015072, 'eval_accuracy': 0.9267435795158172, 'eval_runtime': 3.9603, 'eval_samples_per_second': 820.652, 'eval_steps_per_second': 5.555, 'epoch': 1.0}\n",
      "{'eval_loss': 0.19655659794807434, 'eval_precision': 0.710111966410077, 'eval_recall': 0.7667170381564035, 'eval_f1': 0.7373297002724796, 'eval_accuracy': 0.9443404620907613, 'eval_runtime': 3.9643, 'eval_samples_per_second': 819.818, 'eval_steps_per_second': 5.55, 'epoch': 2.0}\n",
      "{'eval_loss': 0.17069782316684723, 'eval_precision': 0.7380763466455083, 'eval_recall': 0.7907064601435587, 'eval_f1': 0.7634854771784232, 'eval_accuracy': 0.950968058666503, 'eval_runtime': 3.9691, 'eval_samples_per_second': 818.821, 'eval_steps_per_second': 5.543, 'epoch': 3.0}\n",
      "{'eval_loss': 0.15602441132068634, 'eval_precision': 0.7565047509102211, 'eval_recall': 0.8045901020022668, 'eval_f1': 0.7798068561490228, 'eval_accuracy': 0.9549722315976803, 'eval_runtime': 3.8835, 'eval_samples_per_second': 836.88, 'eval_steps_per_second': 5.665, 'epoch': 4.0}\n",
      "{'eval_loss': 0.14727483689785004, 'eval_precision': 0.7706504210714926, 'eval_recall': 0.8124291650925576, 'eval_f1': 0.7909885057471264, 'eval_accuracy': 0.9571814304562609, 'eval_runtime': 4.0121, 'eval_samples_per_second': 810.047, 'eval_steps_per_second': 5.483, 'epoch': 5.0}\n",
      "{'loss': 0.285, 'grad_norm': 1.404719591140747, 'learning_rate': 1.3974358974358975e-05, 'epoch': 5.32}\n",
      "{'eval_loss': 0.14109402894973755, 'eval_precision': 0.7785240909905069, 'eval_recall': 0.8210238005289007, 'eval_f1': 0.7992093408108853, 'eval_accuracy': 0.9589917461875977, 'eval_runtime': 4.0177, 'eval_samples_per_second': 808.925, 'eval_steps_per_second': 5.476, 'epoch': 6.0}\n",
      "{'eval_loss': 0.13705724477767944, 'eval_precision': 0.7829749103942653, 'eval_recall': 0.8252738949754439, 'eval_f1': 0.8035681441971675, 'eval_accuracy': 0.9601423705931085, 'eval_runtime': 3.9488, 'eval_samples_per_second': 823.038, 'eval_steps_per_second': 5.571, 'epoch': 7.0}\n",
      "{'eval_loss': 0.13458751142024994, 'eval_precision': 0.7878406331504632, 'eval_recall': 0.8273517189270873, 'eval_f1': 0.8071129128852443, 'eval_accuracy': 0.9607253536252339, 'eval_runtime': 3.9086, 'eval_samples_per_second': 831.493, 'eval_steps_per_second': 5.629, 'epoch': 8.0}\n",
      "{'eval_loss': 0.13331788778305054, 'eval_precision': 0.7899559787979517, 'eval_recall': 0.8304684548545523, 'eval_f1': 0.8097057875592799, 'eval_accuracy': 0.9612929949986192, 'eval_runtime': 3.8483, 'eval_samples_per_second': 844.534, 'eval_steps_per_second': 5.717, 'epoch': 9.0}\n",
      "{'eval_loss': 0.13294583559036255, 'eval_precision': 0.790282019040776, 'eval_recall': 0.8310351341140915, 'eval_f1': 0.8101463953595434, 'eval_accuracy': 0.96136970329232, 'eval_runtime': 3.8939, 'eval_samples_per_second': 834.649, 'eval_steps_per_second': 5.65, 'epoch': 10.0}\n",
      "{'train_runtime': 188.0846, 'train_samples_per_second': 746.526, 'train_steps_per_second': 4.998, 'train_loss': 0.2265459750561004, 'epoch': 10.0}\n",
      "----------------------------\n",
      "Optimizer: adagrad | Scheduler: cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28139516711235046, 'eval_precision': 0.618368962787015, 'eval_recall': 0.6638647525500566, 'eval_f1': 0.6403097244363471, 'eval_accuracy': 0.9244883556810163, 'eval_runtime': 3.9034, 'eval_samples_per_second': 832.602, 'eval_steps_per_second': 5.636, 'epoch': 1.0}\n",
      "{'eval_loss': 0.19794824719429016, 'eval_precision': 0.7112318205712284, 'eval_recall': 0.7667170381564035, 'eval_f1': 0.7379329151895283, 'eval_accuracy': 0.9448620784879261, 'eval_runtime': 3.851, 'eval_samples_per_second': 843.938, 'eval_steps_per_second': 5.713, 'epoch': 2.0}\n",
      "{'eval_loss': 0.16779176890850067, 'eval_precision': 0.7429803714461755, 'eval_recall': 0.7972232716282585, 'eval_f1': 0.769146658162103, 'eval_accuracy': 0.9521033414132736, 'eval_runtime': 3.9689, 'eval_samples_per_second': 818.867, 'eval_steps_per_second': 5.543, 'epoch': 3.0}\n",
      "{'eval_loss': 0.15220597386360168, 'eval_precision': 0.7669213004085983, 'eval_recall': 0.8154514544767661, 'eval_f1': 0.7904421862125791, 'eval_accuracy': 0.9572274554324813, 'eval_runtime': 3.9007, 'eval_samples_per_second': 833.184, 'eval_steps_per_second': 5.64, 'epoch': 4.0}\n",
      "{'eval_loss': 0.1437273770570755, 'eval_precision': 0.7800644237652111, 'eval_recall': 0.8233849641103136, 'eval_f1': 0.8011394964160999, 'eval_accuracy': 0.9593752876561014, 'eval_runtime': 4.0349, 'eval_samples_per_second': 805.469, 'eval_steps_per_second': 5.452, 'epoch': 5.0}\n",
      "{'loss': 0.2831, 'grad_norm': 1.14810049533844, 'learning_rate': 1.3392022563188283e-05, 'epoch': 5.32}\n",
      "{'eval_loss': 0.13840194046497345, 'eval_precision': 0.7850366923214606, 'eval_recall': 0.8284850774461655, 'eval_f1': 0.8061759029500966, 'eval_accuracy': 0.9605872786965727, 'eval_runtime': 3.891, 'eval_samples_per_second': 835.256, 'eval_steps_per_second': 5.654, 'epoch': 6.0}\n",
      "{'eval_loss': 0.13562233746051788, 'eval_precision': 0.7876351290985437, 'eval_recall': 0.8326407253494522, 'eval_f1': 0.8095128781965933, 'eval_accuracy': 0.9614003866098002, 'eval_runtime': 3.9434, 'eval_samples_per_second': 824.159, 'eval_steps_per_second': 5.579, 'epoch': 7.0}\n",
      "{'eval_loss': 0.13425825536251068, 'eval_precision': 0.7899919434249396, 'eval_recall': 0.8334907442387609, 'eval_f1': 0.8111586010386507, 'eval_accuracy': 0.961691878125863, 'eval_runtime': 3.8615, 'eval_samples_per_second': 841.651, 'eval_steps_per_second': 5.697, 'epoch': 8.0}\n",
      "{'eval_loss': 0.13379499316215515, 'eval_precision': 0.7907642742079828, 'eval_recall': 0.8345296562145825, 'eval_f1': 0.8120577152835217, 'eval_accuracy': 0.9619220030069651, 'eval_runtime': 3.9817, 'eval_samples_per_second': 816.228, 'eval_steps_per_second': 5.525, 'epoch': 9.0}\n",
      "{'eval_loss': 0.1337493360042572, 'eval_precision': 0.7909619686800895, 'eval_recall': 0.8348129958443521, 'eval_f1': 0.812296098883426, 'eval_accuracy': 0.9619373446657052, 'eval_runtime': 3.8578, 'eval_samples_per_second': 842.448, 'eval_steps_per_second': 5.703, 'epoch': 10.0}\n",
      "{'train_runtime': 186.426, 'train_samples_per_second': 753.168, 'train_steps_per_second': 5.042, 'train_loss': 0.22436290497475483, 'epoch': 10.0}\n",
      "----------------------------\n",
      "Optimizer: adagrad | Scheduler: polynomial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29934048652648926, 'eval_precision': 0.5962062000526916, 'eval_recall': 0.6411975821684927, 'eval_f1': 0.6178839590443685, 'eval_accuracy': 0.9192875333681078, 'eval_runtime': 3.8821, 'eval_samples_per_second': 837.178, 'eval_steps_per_second': 5.667, 'epoch': 1.0}\n",
      "{'eval_loss': 0.22242829203605652, 'eval_precision': 0.6837509822753863, 'eval_recall': 0.7396108802417831, 'eval_f1': 0.7105848192005807, 'eval_accuracy': 0.9389401982142309, 'eval_runtime': 3.8754, 'eval_samples_per_second': 838.615, 'eval_steps_per_second': 5.677, 'epoch': 2.0}\n",
      "{'eval_loss': 0.1935511827468872, 'eval_precision': 0.7123072903057225, 'eval_recall': 0.7723838307517945, 'eval_f1': 0.7411300919842312, 'eval_accuracy': 0.9456751864011537, 'eval_runtime': 4.5576, 'eval_samples_per_second': 713.092, 'eval_steps_per_second': 4.827, 'epoch': 3.0}\n",
      "{'eval_loss': 0.18016143143177032, 'eval_precision': 0.7315641968821159, 'eval_recall': 0.7889119758216849, 'eval_f1': 0.7591565936562755, 'eval_accuracy': 0.9494799177687091, 'eval_runtime': 3.9604, 'eval_samples_per_second': 820.622, 'eval_steps_per_second': 5.555, 'epoch': 4.0}\n",
      "{'eval_loss': 0.17293959856033325, 'eval_precision': 0.7388282899366643, 'eval_recall': 0.7932565168114847, 'eval_f1': 0.7650756057569684, 'eval_accuracy': 0.9511214752539044, 'eval_runtime': 3.8685, 'eval_samples_per_second': 840.115, 'eval_steps_per_second': 5.687, 'epoch': 5.0}\n",
      "{'loss': 0.3092, 'grad_norm': 1.234157919883728, 'learning_rate': 6.58772554605888e-06, 'epoch': 5.32}\n",
      "{'eval_loss': 0.1688489019870758, 'eval_precision': 0.7424349049964813, 'eval_recall': 0.7971288250850019, 'eval_f1': 0.7688103479686645, 'eval_accuracy': 0.952041974778313, 'eval_runtime': 4.1291, 'eval_samples_per_second': 787.088, 'eval_steps_per_second': 5.328, 'epoch': 6.0}\n",
      "{'eval_loss': 0.1669256091117859, 'eval_precision': 0.7442126573365021, 'eval_recall': 0.7985455232338496, 'eval_f1': 0.77042234270354, 'eval_accuracy': 0.9525329078579976, 'eval_runtime': 3.9958, 'eval_samples_per_second': 813.362, 'eval_steps_per_second': 5.506, 'epoch': 7.0}\n",
      "{'eval_loss': 0.16586633026599884, 'eval_precision': 0.746079295154185, 'eval_recall': 0.7997733282961843, 'eval_f1': 0.7719938007110949, 'eval_accuracy': 0.9528243993740603, 'eval_runtime': 4.0378, 'eval_samples_per_second': 804.901, 'eval_steps_per_second': 5.449, 'epoch': 8.0}\n",
      "{'eval_loss': 0.16548708081245422, 'eval_precision': 0.746717193971975, 'eval_recall': 0.8002455610124669, 'eval_f1': 0.7725552769546387, 'eval_accuracy': 0.9529931576202019, 'eval_runtime': 4.0743, 'eval_samples_per_second': 797.684, 'eval_steps_per_second': 5.4, 'epoch': 9.0}\n",
      "{'eval_loss': 0.16541124880313873, 'eval_precision': 0.747025121198766, 'eval_recall': 0.80043445409898, 'eval_f1': 0.7728080973874983, 'eval_accuracy': 0.9530238409376822, 'eval_runtime': 4.0042, 'eval_samples_per_second': 811.65, 'eval_steps_per_second': 5.494, 'epoch': 10.0}\n",
      "{'train_runtime': 190.1241, 'train_samples_per_second': 738.518, 'train_steps_per_second': 4.944, 'train_loss': 0.25650560906592834, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "df = pii.train(\n",
    "    output_dir = \"test/\",\n",
    "    optimizers = optimizers,\n",
    "    schedulers = schedulers,\n",
    "    tokenizer_path = model_path,\n",
    "    model_path = model_path,\n",
    "    strategy = \"epoch\",\n",
    "    epochs = 10,\n",
    "    batch_size = 150,\n",
    "    result_csv = \"test.csv\",\n",
    "    device = \"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.725335955424451,\n",
       "  'recall': 0.8136029411764706,\n",
       "  'f1': 0.7669381389707157,\n",
       "  'number': 2720},\n",
       " 'MISC': {'precision': 0.5721877767936226,\n",
       "  'recall': 0.5632083696599826,\n",
       "  'f1': 0.5676625659050966,\n",
       "  'number': 1147},\n",
       " 'ORG': {'precision': 0.7049830124575311,\n",
       "  'recall': 0.7699443413729128,\n",
       "  'f1': 0.7360331067100208,\n",
       "  'number': 3234},\n",
       " 'PER': {'precision': 0.9152076896670099,\n",
       "  'recall': 0.9302163293789253,\n",
       "  'f1': 0.9226509776777988,\n",
       "  'number': 2866},\n",
       " 'overall_precision': 0.7543529411764706,\n",
       " 'overall_recall': 0.8041537072338718,\n",
       " 'overall_f1': 0.7784576534576535,\n",
       " 'overall_accuracy': 0.9518529567753912,\n",
       " 'train_time': 193.58787441253662,\n",
       " 'log': [{'eval_loss': 0.27008575201034546,\n",
       "   'eval_precision': 0.647475015477138,\n",
       "   'eval_recall': 0.6914431431809596,\n",
       "   'eval_f1': 0.6687371546015072,\n",
       "   'eval_accuracy': 0.9267435795158172,\n",
       "   'eval_runtime': 3.9603,\n",
       "   'eval_samples_per_second': 820.652,\n",
       "   'eval_steps_per_second': 5.555,\n",
       "   'epoch': 1.0,\n",
       "   'step': 94},\n",
       "  {'eval_loss': 0.19655659794807434,\n",
       "   'eval_precision': 0.710111966410077,\n",
       "   'eval_recall': 0.7667170381564035,\n",
       "   'eval_f1': 0.7373297002724796,\n",
       "   'eval_accuracy': 0.9443404620907613,\n",
       "   'eval_runtime': 3.9643,\n",
       "   'eval_samples_per_second': 819.818,\n",
       "   'eval_steps_per_second': 5.55,\n",
       "   'epoch': 2.0,\n",
       "   'step': 188},\n",
       "  {'eval_loss': 0.17069782316684723,\n",
       "   'eval_precision': 0.7380763466455083,\n",
       "   'eval_recall': 0.7907064601435587,\n",
       "   'eval_f1': 0.7634854771784232,\n",
       "   'eval_accuracy': 0.950968058666503,\n",
       "   'eval_runtime': 3.9691,\n",
       "   'eval_samples_per_second': 818.821,\n",
       "   'eval_steps_per_second': 5.543,\n",
       "   'epoch': 3.0,\n",
       "   'step': 282},\n",
       "  {'eval_loss': 0.15602441132068634,\n",
       "   'eval_precision': 0.7565047509102211,\n",
       "   'eval_recall': 0.8045901020022668,\n",
       "   'eval_f1': 0.7798068561490228,\n",
       "   'eval_accuracy': 0.9549722315976803,\n",
       "   'eval_runtime': 3.8835,\n",
       "   'eval_samples_per_second': 836.88,\n",
       "   'eval_steps_per_second': 5.665,\n",
       "   'epoch': 4.0,\n",
       "   'step': 376},\n",
       "  {'eval_loss': 0.14727483689785004,\n",
       "   'eval_precision': 0.7706504210714926,\n",
       "   'eval_recall': 0.8124291650925576,\n",
       "   'eval_f1': 0.7909885057471264,\n",
       "   'eval_accuracy': 0.9571814304562609,\n",
       "   'eval_runtime': 4.0121,\n",
       "   'eval_samples_per_second': 810.047,\n",
       "   'eval_steps_per_second': 5.483,\n",
       "   'epoch': 5.0,\n",
       "   'step': 470},\n",
       "  {'loss': 0.285,\n",
       "   'grad_norm': 1.404719591140747,\n",
       "   'learning_rate': 1.3974358974358975e-05,\n",
       "   'epoch': 5.32,\n",
       "   'step': 500},\n",
       "  {'eval_loss': 0.14109402894973755,\n",
       "   'eval_precision': 0.7785240909905069,\n",
       "   'eval_recall': 0.8210238005289007,\n",
       "   'eval_f1': 0.7992093408108853,\n",
       "   'eval_accuracy': 0.9589917461875977,\n",
       "   'eval_runtime': 4.0177,\n",
       "   'eval_samples_per_second': 808.925,\n",
       "   'eval_steps_per_second': 5.476,\n",
       "   'epoch': 6.0,\n",
       "   'step': 564},\n",
       "  {'eval_loss': 0.13705724477767944,\n",
       "   'eval_precision': 0.7829749103942653,\n",
       "   'eval_recall': 0.8252738949754439,\n",
       "   'eval_f1': 0.8035681441971675,\n",
       "   'eval_accuracy': 0.9601423705931085,\n",
       "   'eval_runtime': 3.9488,\n",
       "   'eval_samples_per_second': 823.038,\n",
       "   'eval_steps_per_second': 5.571,\n",
       "   'epoch': 7.0,\n",
       "   'step': 658},\n",
       "  {'eval_loss': 0.13458751142024994,\n",
       "   'eval_precision': 0.7878406331504632,\n",
       "   'eval_recall': 0.8273517189270873,\n",
       "   'eval_f1': 0.8071129128852443,\n",
       "   'eval_accuracy': 0.9607253536252339,\n",
       "   'eval_runtime': 3.9086,\n",
       "   'eval_samples_per_second': 831.493,\n",
       "   'eval_steps_per_second': 5.629,\n",
       "   'epoch': 8.0,\n",
       "   'step': 752},\n",
       "  {'eval_loss': 0.13331788778305054,\n",
       "   'eval_precision': 0.7899559787979517,\n",
       "   'eval_recall': 0.8304684548545523,\n",
       "   'eval_f1': 0.8097057875592799,\n",
       "   'eval_accuracy': 0.9612929949986192,\n",
       "   'eval_runtime': 3.8483,\n",
       "   'eval_samples_per_second': 844.534,\n",
       "   'eval_steps_per_second': 5.717,\n",
       "   'epoch': 9.0,\n",
       "   'step': 846},\n",
       "  {'eval_loss': 0.13294583559036255,\n",
       "   'eval_precision': 0.790282019040776,\n",
       "   'eval_recall': 0.8310351341140915,\n",
       "   'eval_f1': 0.8101463953595434,\n",
       "   'eval_accuracy': 0.96136970329232,\n",
       "   'eval_runtime': 3.8939,\n",
       "   'eval_samples_per_second': 834.649,\n",
       "   'eval_steps_per_second': 5.65,\n",
       "   'epoch': 10.0,\n",
       "   'step': 940},\n",
       "  {'train_runtime': 188.0846,\n",
       "   'train_samples_per_second': 746.526,\n",
       "   'train_steps_per_second': 4.998,\n",
       "   'total_flos': 2288434955691150.0,\n",
       "   'train_loss': 0.2265459750561004,\n",
       "   'epoch': 10.0,\n",
       "   'step': 940}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.at[\"adagrad\",\"linear\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melanoma identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = load_dataset(path = \"ai4privacy/pii-masking-200k\", data_files = \"english_pii_43k.jsonl\")\n",
    "dataset = load_dataset(path = \"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.RobertaTokenizerFast.from_pretrained(model_path, add_prefix_space = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples, label_all_tokens = True):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"],\n",
    "        truncation = True, \n",
    "        is_split_into_words = True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index = i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|| 14041/14041 [00:01<00:00, 8256.26 examples/s]\n",
      "Map: 100%|| 3250/3250 [00:00<00:00, 8099.45 examples/s]\n",
      "Map: 100%|| 3453/3453 [00:00<00:00, 9232.67 examples/s]\n"
     ]
    }
   ],
   "source": [
    "toknized_dataset = dataset.map(tokenize_and_align_labels, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|| 3.24k/3.24k [00:00<?, ?B/s]\n",
      "Downloading data: 100%|| 521M/521M [01:21<00:00, 6.37MB/s] \n",
      "Downloading data: 100%|| 525M/525M [01:24<00:00, 6.24MB/s] \n",
      "Downloading data: 100%|| 527M/527M [01:24<00:00, 6.23MB/s] \n",
      "Downloading data: 100%|| 528M/528M [01:19<00:00, 6.60MB/s] \n",
      "Downloading data: 100%|| 548M/548M [01:26<00:00, 6.33MB/s] \n",
      "Downloading data: 100%|| 341M/341M [00:48<00:00, 7.03MB/s] \n",
      "Downloading data: 100%|| 348M/348M [00:48<00:00, 7.21MB/s] \n",
      "Downloading data: 100%|| 355M/355M [00:54<00:00, 6.46MB/s] \n",
      "Generating train split: 100%|| 9577/9577 [00:04<00:00, 2388.92 examples/s]\n",
      "Generating validation split: 100%|| 2492/2492 [00:01<00:00, 2204.03 examples/s]\n",
      "Generating test split: 100%|| 1285/1285 [00:00<00:00, 2136.98 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"marmal88/skin_cancer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=600x450>,\n",
       " 'image_id': 'ISIC_0024329',\n",
       " 'lesion_id': 'HAM_0002954',\n",
       " 'dx': 'actinic_keratoses',\n",
       " 'dx_type': 'histo',\n",
       " 'age': 75.0,\n",
       " 'sex': 'female',\n",
       " 'localization': 'lower extremity'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD Algorithms: \n",
    "- \"adamw_torch\"\n",
    "- \"adagrad\"\n",
    "- \"rmsprop\"\n",
    "\n",
    "\n",
    "LR Schedulers:\n",
    "\n",
    "- \"cosine\"\n",
    "- \"inverse_sqrt\"\n",
    "\n",
    "inverse_sqrt = lambda step: 1/math.sqrt(step, 100)\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda = inverse_sqrt)\n",
    "\n",
    "\n",
    "- \"reduce_lr_on_plateau\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "515_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
