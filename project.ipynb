{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "from project import CreditDefault, PII, SkinCancer, set_seed\n",
    "\n",
    "set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credit-card default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = CreditDefault()\n",
    "credit.prepare_dataset(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    \"adamw\": (torch.optim.AdamW, {\"lr\": 2e-5}),\n",
    "    \"rmsprop\": (torch.optim.RMSprop, {\"lr\": 2e-5}),\n",
    "    \"adagrad\": (torch.optim.Adagrad, {\"lr\": 2e-5}),\n",
    "}\n",
    "\n",
    "schedulers = {\n",
    "    \"linear\": (torch.optim.lr_scheduler.LinearLR, {\"start_factor\": 0.01, \"end_factor\": 0.0001, \"total_iters\": 2}),\n",
    "    \"cosine\": (torch.optim.lr_scheduler.CosineAnnealing, {\"T_max\": 100, \"eta_min\": 0.01}),\n",
    "    \"polynomial\": (torch.optim.lr_scheduler.PolynomialLR, {\"total_iters\": 100, \"power\": 2})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "|linear, adamw|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.4424096345901489 | accuracy: 0.537\n",
      "\tbatch 2 | loss: 0.4221212863922119 | accuracy: 0.556\n",
      "\tbatch 3 | loss: 0.41576284170150757 | accuracy: 0.563\n",
      "\tbatch 4 | loss: 0.3999929428100586 | accuracy: 0.584\n",
      "\tbatch 5 | loss: 0.3750000596046448 | accuracy: 0.605\n",
      "\tbatch 6 | loss: 0.35946759581565857 | accuracy: 0.618\n",
      "\tbatch 7 | loss: 0.3029974699020386 | accuracy: 0.673\n",
      "\tbatch 8 | loss: 0.3039945960044861 | accuracy: 0.68\n",
      "\tbatch 9 | loss: 0.24527829885482788 | accuracy: 0.725\n",
      "\tbatch 10 | loss: 0.24620354175567627 | accuracy: 0.715\n",
      "\tbatch 11 | loss: 0.2339823693037033 | accuracy: 0.742\n",
      "\tbatch 12 | loss: 0.23700402677059174 | accuracy: 0.746\n",
      "\tbatch 13 | loss: 0.22199484705924988 | accuracy: 0.767\n",
      "\tbatch 14 | loss: 0.2247716784477234 | accuracy: 0.767\n",
      "\tbatch 15 | loss: 0.23900000751018524 | accuracy: 0.755\n",
      "\tbatch 16 | loss: 0.2389996200799942 | accuracy: 0.753\n",
      "\tbatch 17 | loss: 0.2141554355621338 | accuracy: 0.78\n",
      "\tbatch 18 | loss: 0.21477627754211426 | accuracy: 0.781\n",
      "\tbatch 19 | loss: 0.20200000703334808 | accuracy: 0.796\n",
      "\tbatch 20 | loss: 0.23400211334228516 | accuracy: 0.762\n",
      "\tbatch 21 | loss: 0.23200000822544098 | accuracy: 0.767\n",
      "\tbatch 22 | loss: 0.21399931609630585 | accuracy: 0.783\n",
      "\tbatch 23 | loss: 0.244003564119339 | accuracy: 0.754\n",
      "\tbatch 24 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 1 | loss: 0.2290000170469284 | accuracy: 0.769\n",
      "\tbatch 2 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 3 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 4 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 5 | loss: 0.22100001573562622 | accuracy: 0.776\n",
      "\tbatch 6 | loss: 0.21900001168251038 | accuracy: 0.78\n",
      "\tAverage accuracy 0.777\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 2 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 3 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 4 | loss: 0.22200001776218414 | accuracy: 0.775\n",
      "\tbatch 5 | loss: 0.24300001561641693 | accuracy: 0.756\n",
      "\tbatch 6 | loss: 0.20800000429153442 | accuracy: 0.789\n",
      "\tbatch 7 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 8 | loss: 0.22500000894069672 | accuracy: 0.773\n",
      "\tbatch 9 | loss: 0.22800001502037048 | accuracy: 0.771\n",
      "\tbatch 10 | loss: 0.22098027169704437 | accuracy: 0.779\n",
      "\tbatch 11 | loss: 0.23200000822544098 | accuracy: 0.767\n",
      "\tbatch 12 | loss: 0.19700001180171967 | accuracy: 0.802\n",
      "\tbatch 13 | loss: 0.21900001168251038 | accuracy: 0.78\n",
      "\tbatch 14 | loss: 0.2200000137090683 | accuracy: 0.777\n",
      "\tbatch 15 | loss: 0.22020161151885986 | accuracy: 0.779\n",
      "\tbatch 16 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 17 | loss: 0.20600001513957977 | accuracy: 0.793\n",
      "\tbatch 18 | loss: 0.23199857771396637 | accuracy: 0.767\n",
      "\tbatch 19 | loss: 0.24500000476837158 | accuracy: 0.755\n",
      "\tbatch 20 | loss: 0.2144433706998825 | accuracy: 0.783\n",
      "\tbatch 21 | loss: 0.23000000417232513 | accuracy: 0.769\n",
      "\tbatch 22 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 23 | loss: 0.2200000137090683 | accuracy: 0.779\n",
      "\tbatch 24 | loss: 0.23900000751018524 | accuracy: 0.76\n",
      "\tbatch 1 | loss: 0.19200000166893005 | accuracy: 0.808\n",
      "\tbatch 2 | loss: 0.2439984828233719 | accuracy: 0.756\n",
      "\tbatch 3 | loss: 0.23799890279769897 | accuracy: 0.762\n",
      "\tbatch 4 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 5 | loss: 0.22299890220165253 | accuracy: 0.777\n",
      "\tbatch 6 | loss: 0.21900001168251038 | accuracy: 0.78\n",
      "\tAverage accuracy 0.7783333333333333\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 2 | loss: 0.2299986034631729 | accuracy: 0.767\n",
      "\tbatch 3 | loss: 0.23799994587898254 | accuracy: 0.762\n",
      "\tbatch 4 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 5 | loss: 0.22300000488758087 | accuracy: 0.774\n",
      "\tbatch 6 | loss: 0.22500000894069672 | accuracy: 0.774\n",
      "\tbatch 7 | loss: 0.23900000751018524 | accuracy: 0.761\n",
      "\tbatch 8 | loss: 0.2370000183582306 | accuracy: 0.762\n",
      "\tbatch 9 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 10 | loss: 0.20900000631809235 | accuracy: 0.79\n",
      "\tbatch 11 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 12 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 13 | loss: 0.22300000488758087 | accuracy: 0.776\n",
      "\tbatch 14 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 15 | loss: 0.21300001442432404 | accuracy: 0.786\n",
      "\tbatch 16 | loss: 0.22800001502037048 | accuracy: 0.771\n",
      "\tbatch 17 | loss: 0.23900000751018524 | accuracy: 0.761\n",
      "\tbatch 18 | loss: 0.23500001430511475 | accuracy: 0.764\n",
      "\tbatch 19 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 20 | loss: 0.23000000417232513 | accuracy: 0.769\n",
      "\tbatch 21 | loss: 0.23400001227855682 | accuracy: 0.763\n",
      "\tbatch 22 | loss: 0.2150000035762787 | accuracy: 0.782\n",
      "\tbatch 23 | loss: 0.21800000965595245 | accuracy: 0.78\n",
      "\tbatch 24 | loss: 0.21200016140937805 | accuracy: 0.786\n",
      "\tbatch 1 | loss: 0.21900001168251038 | accuracy: 0.78\n",
      "\tbatch 2 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 3 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 4 | loss: 0.22899110615253448 | accuracy: 0.771\n",
      "\tbatch 5 | loss: 0.21499904990196228 | accuracy: 0.785\n",
      "\tbatch 6 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tAverage accuracy 0.7783333333333333\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.22700001299381256 | accuracy: 0.771\n",
      "\tbatch 2 | loss: 0.20100000500679016 | accuracy: 0.799\n",
      "\tbatch 3 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 4 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 5 | loss: 0.22600001096725464 | accuracy: 0.773\n",
      "\tbatch 6 | loss: 0.23600001633167267 | accuracy: 0.763\n",
      "\tbatch 7 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 8 | loss: 0.22899994254112244 | accuracy: 0.768\n",
      "\tbatch 9 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 10 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 11 | loss: 0.22200001776218414 | accuracy: 0.776\n",
      "\tbatch 12 | loss: 0.22800001502037048 | accuracy: 0.769\n",
      "\tbatch 13 | loss: 0.23800000548362732 | accuracy: 0.761\n",
      "\tbatch 14 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 15 | loss: 0.21900001168251038 | accuracy: 0.78\n",
      "\tbatch 16 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 17 | loss: 0.19600000977516174 | accuracy: 0.802\n",
      "\tbatch 18 | loss: 0.22700001299381256 | accuracy: 0.772\n",
      "\tbatch 19 | loss: 0.18700025975704193 | accuracy: 0.81\n",
      "\tbatch 20 | loss: 0.2059977650642395 | accuracy: 0.793\n",
      "\tbatch 21 | loss: 0.2200000137090683 | accuracy: 0.779\n",
      "\tbatch 22 | loss: 0.23500004410743713 | accuracy: 0.763\n",
      "\tbatch 23 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tbatch 24 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 1 | loss: 0.21798498928546906 | accuracy: 0.782\n",
      "\tbatch 2 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 3 | loss: 0.242000013589859 | accuracy: 0.757\n",
      "\tbatch 4 | loss: 0.2249990701675415 | accuracy: 0.775\n",
      "\tbatch 5 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 6 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tAverage accuracy 0.7783333333333333\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.21000000834465027 | accuracy: 0.787\n",
      "\tbatch 2 | loss: 0.22200001776218414 | accuracy: 0.776\n",
      "\tbatch 3 | loss: 0.2110000103712082 | accuracy: 0.786\n",
      "\tbatch 4 | loss: 0.2290000170469284 | accuracy: 0.77\n",
      "\tbatch 5 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 6 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 7 | loss: 0.217997744679451 | accuracy: 0.782\n",
      "\tbatch 8 | loss: 0.22200001776218414 | accuracy: 0.777\n",
      "\tbatch 9 | loss: 0.23000000417232513 | accuracy: 0.768\n",
      "\tbatch 10 | loss: 0.22100001573562622 | accuracy: 0.778\n",
      "\tbatch 11 | loss: 0.19600000977516174 | accuracy: 0.804\n",
      "\tbatch 12 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 13 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 14 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 15 | loss: 0.2330000102519989 | accuracy: 0.766\n",
      "\tbatch 16 | loss: 0.19500000774860382 | accuracy: 0.805\n",
      "\tbatch 17 | loss: 0.2229999452829361 | accuracy: 0.777\n",
      "\tbatch 18 | loss: 0.23100000619888306 | accuracy: 0.768\n",
      "\tbatch 19 | loss: 0.24900004267692566 | accuracy: 0.75\n",
      "\tbatch 20 | loss: 0.24700000882148743 | accuracy: 0.75\n",
      "\tbatch 21 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 22 | loss: 0.21700000762939453 | accuracy: 0.78\n",
      "\tbatch 23 | loss: 0.19700001180171967 | accuracy: 0.803\n",
      "\tbatch 24 | loss: 0.2540002465248108 | accuracy: 0.744\n",
      "\tbatch 1 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 2 | loss: 0.2199990600347519 | accuracy: 0.78\n",
      "\tbatch 3 | loss: 0.21997995674610138 | accuracy: 0.78\n",
      "\tbatch 4 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 5 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 6 | loss: 0.20199817419052124 | accuracy: 0.797\n",
      "\tAverage accuracy 0.7783333333333333\n",
      "-------------------------------------\n",
      "|linear, rmsprop|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.6150901913642883 | accuracy: 0.36\n",
      "\tbatch 2 | loss: 0.24399994313716888 | accuracy: 0.752\n",
      "\tbatch 3 | loss: 0.2539984881877899 | accuracy: 0.741\n",
      "\tbatch 4 | loss: 0.22069096565246582 | accuracy: 0.771\n",
      "\tbatch 5 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 6 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 7 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 8 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 9 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 10 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 11 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 12 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 13 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 14 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 15 | loss: 0.1990000158548355 | accuracy: 0.801\n",
      "\tbatch 16 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 17 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 18 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 19 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 20 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 21 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 22 | loss: 0.1990000158548355 | accuracy: 0.801\n",
      "\tbatch 23 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 24 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 1 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 2 | loss: 0.24300001561641693 | accuracy: 0.757\n",
      "\tbatch 3 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 4 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 5 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 6 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 2 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 3 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 4 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 5 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 6 | loss: 0.25 | accuracy: 0.75\n",
      "\tbatch 7 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 8 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 9 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 10 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 11 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 12 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 13 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 14 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 15 | loss: 0.19700001180171967 | accuracy: 0.803\n",
      "\tbatch 16 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 17 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 18 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 19 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 20 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 21 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 22 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 23 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 24 | loss: 0.21700000762939453 | accuracy: 0.782\n",
      "\tbatch 1 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 2 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 3 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 4 | loss: 0.23900000751018524 | accuracy: 0.761\n",
      "\tbatch 5 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 6 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 2 | loss: 0.20499996840953827 | accuracy: 0.795\n",
      "\tbatch 3 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 4 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 5 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 6 | loss: 0.24400001764297485 | accuracy: 0.756\n",
      "\tbatch 7 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 8 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 9 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 10 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 11 | loss: 0.25 | accuracy: 0.75\n",
      "\tbatch 12 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 13 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 14 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 15 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 16 | loss: 0.20900000631809235 | accuracy: 0.79\n",
      "\tbatch 17 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 18 | loss: 0.25300002098083496 | accuracy: 0.747\n",
      "\tbatch 19 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 20 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 21 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 22 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 23 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 24 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 1 | loss: 0.19300000369548798 | accuracy: 0.807\n",
      "\tbatch 2 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 3 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 4 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 5 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 6 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.21199969947338104 | accuracy: 0.788\n",
      "\tbatch 2 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 3 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 4 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 5 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 6 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 7 | loss: 0.24300001561641693 | accuracy: 0.757\n",
      "\tbatch 8 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 9 | loss: 0.2460000067949295 | accuracy: 0.753\n",
      "\tbatch 10 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 11 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 12 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 13 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 14 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 15 | loss: 0.18700000643730164 | accuracy: 0.813\n",
      "\tbatch 16 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 17 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 18 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 19 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 20 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 21 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 22 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 23 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 24 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 1 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 2 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 3 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 4 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 5 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 6 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 2 | loss: 0.19600000977516174 | accuracy: 0.803\n",
      "\tbatch 3 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 4 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 5 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 6 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 7 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 8 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 9 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 10 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 11 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 12 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 13 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 14 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 15 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 16 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 17 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 18 | loss: 0.24598655104637146 | accuracy: 0.754\n",
      "\tbatch 19 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 20 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 21 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 22 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 23 | loss: 0.2410000115633011 | accuracy: 0.759\n",
      "\tbatch 24 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 1 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 2 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 3 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 4 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 5 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 6 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "-------------------------------------\n",
      "|linear, adagrad|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.2150000035762787 | accuracy: 0.782\n",
      "\tbatch 2 | loss: 0.20500001311302185 | accuracy: 0.793\n",
      "\tbatch 3 | loss: 0.21799997985363007 | accuracy: 0.779\n",
      "\tbatch 4 | loss: 0.21899960935115814 | accuracy: 0.777\n",
      "\tbatch 5 | loss: 0.242000013589859 | accuracy: 0.748\n",
      "\tbatch 6 | loss: 0.23999832570552826 | accuracy: 0.757\n",
      "\tbatch 7 | loss: 0.23800000548362732 | accuracy: 0.758\n",
      "\tbatch 8 | loss: 0.2190966010093689 | accuracy: 0.776\n",
      "\tbatch 9 | loss: 0.2099999189376831 | accuracy: 0.788\n",
      "\tbatch 10 | loss: 0.20200000703334808 | accuracy: 0.796\n",
      "\tbatch 11 | loss: 0.2160000056028366 | accuracy: 0.781\n",
      "\tbatch 12 | loss: 0.22600001096725464 | accuracy: 0.773\n",
      "\tbatch 13 | loss: 0.20000000298023224 | accuracy: 0.797\n",
      "\tbatch 14 | loss: 0.2160000056028366 | accuracy: 0.779\n",
      "\tbatch 15 | loss: 0.2477458417415619 | accuracy: 0.749\n",
      "\tbatch 16 | loss: 0.21399623155593872 | accuracy: 0.785\n",
      "\tbatch 17 | loss: 0.22700001299381256 | accuracy: 0.771\n",
      "\tbatch 18 | loss: 0.2330000102519989 | accuracy: 0.761\n",
      "\tbatch 19 | loss: 0.22500000894069672 | accuracy: 0.772\n",
      "\tbatch 20 | loss: 0.23100002110004425 | accuracy: 0.763\n",
      "\tbatch 21 | loss: 0.23169036209583282 | accuracy: 0.766\n",
      "\tbatch 22 | loss: 0.19500000774860382 | accuracy: 0.803\n",
      "\tbatch 23 | loss: 0.2290000170469284 | accuracy: 0.767\n",
      "\tbatch 24 | loss: 0.26200026273727417 | accuracy: 0.734\n",
      "\tbatch 1 | loss: 0.23200000822544098 | accuracy: 0.764\n",
      "\tbatch 2 | loss: 0.22000351548194885 | accuracy: 0.776\n",
      "\tbatch 3 | loss: 0.21000000834465027 | accuracy: 0.789\n",
      "\tbatch 4 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 5 | loss: 0.22300000488758087 | accuracy: 0.775\n",
      "\tbatch 6 | loss: 0.23800000548362732 | accuracy: 0.759\n",
      "\tAverage accuracy 0.7771666666666667\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.21900001168251038 | accuracy: 0.779\n",
      "\tbatch 2 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 3 | loss: 0.2120000123977661 | accuracy: 0.784\n",
      "\tbatch 4 | loss: 0.22700001299381256 | accuracy: 0.771\n",
      "\tbatch 5 | loss: 0.21000000834465027 | accuracy: 0.786\n",
      "\tbatch 6 | loss: 0.2300039827823639 | accuracy: 0.767\n",
      "\tbatch 7 | loss: 0.22500000894069672 | accuracy: 0.772\n",
      "\tbatch 8 | loss: 0.22700001299381256 | accuracy: 0.772\n",
      "\tbatch 9 | loss: 0.22100001573562622 | accuracy: 0.775\n",
      "\tbatch 10 | loss: 0.21000000834465027 | accuracy: 0.787\n",
      "\tbatch 11 | loss: 0.22100019454956055 | accuracy: 0.776\n",
      "\tbatch 12 | loss: 0.23800000548362732 | accuracy: 0.761\n",
      "\tbatch 13 | loss: 0.21700000762939453 | accuracy: 0.779\n",
      "\tbatch 14 | loss: 0.2240000069141388 | accuracy: 0.774\n",
      "\tbatch 15 | loss: 0.22300000488758087 | accuracy: 0.772\n",
      "\tbatch 16 | loss: 0.22500000894069672 | accuracy: 0.773\n",
      "\tbatch 17 | loss: 0.21999989449977875 | accuracy: 0.778\n",
      "\tbatch 18 | loss: 0.22200001776218414 | accuracy: 0.774\n",
      "\tbatch 19 | loss: 0.2120000123977661 | accuracy: 0.787\n",
      "\tbatch 20 | loss: 0.23600001633167267 | accuracy: 0.759\n",
      "\tbatch 21 | loss: 0.23000000417232513 | accuracy: 0.766\n",
      "\tbatch 22 | loss: 0.22174499928951263 | accuracy: 0.771\n",
      "\tbatch 23 | loss: 0.22100001573562622 | accuracy: 0.776\n",
      "\tbatch 24 | loss: 0.21800000965595245 | accuracy: 0.778\n",
      "\tbatch 1 | loss: 0.21545447409152985 | accuracy: 0.783\n",
      "\tbatch 2 | loss: 0.21699997782707214 | accuracy: 0.781\n",
      "\tbatch 3 | loss: 0.21800008416175842 | accuracy: 0.778\n",
      "\tbatch 4 | loss: 0.22500000894069672 | accuracy: 0.773\n",
      "\tbatch 5 | loss: 0.24900001287460327 | accuracy: 0.75\n",
      "\tbatch 6 | loss: 0.1990000158548355 | accuracy: 0.796\n",
      "\tAverage accuracy 0.7768333333333334\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.22200001776218414 | accuracy: 0.777\n",
      "\tbatch 2 | loss: 0.21200017631053925 | accuracy: 0.784\n",
      "\tbatch 3 | loss: 0.2150000035762787 | accuracy: 0.783\n",
      "\tbatch 4 | loss: 0.2110000103712082 | accuracy: 0.786\n",
      "\tbatch 5 | loss: 0.22600001096725464 | accuracy: 0.773\n",
      "\tbatch 6 | loss: 0.18800033628940582 | accuracy: 0.803\n",
      "\tbatch 7 | loss: 0.22600001096725464 | accuracy: 0.772\n",
      "\tbatch 8 | loss: 0.23704905807971954 | accuracy: 0.759\n",
      "\tbatch 9 | loss: 0.20400001108646393 | accuracy: 0.791\n",
      "\tbatch 10 | loss: 0.20899976789951324 | accuracy: 0.787\n",
      "\tbatch 11 | loss: 0.22700001299381256 | accuracy: 0.769\n",
      "\tbatch 12 | loss: 0.23400001227855682 | accuracy: 0.764\n",
      "\tbatch 13 | loss: 0.23400001227855682 | accuracy: 0.764\n",
      "\tbatch 14 | loss: 0.22600001096725464 | accuracy: 0.771\n",
      "\tbatch 15 | loss: 0.22399862110614777 | accuracy: 0.772\n",
      "\tbatch 16 | loss: 0.2048245519399643 | accuracy: 0.793\n",
      "\tbatch 17 | loss: 0.22100143134593964 | accuracy: 0.776\n",
      "\tbatch 18 | loss: 0.2290000170469284 | accuracy: 0.77\n",
      "\tbatch 19 | loss: 0.21217888593673706 | accuracy: 0.785\n",
      "\tbatch 20 | loss: 0.21700000762939453 | accuracy: 0.781\n",
      "\tbatch 21 | loss: 0.2370000183582306 | accuracy: 0.76\n",
      "\tbatch 22 | loss: 0.2380134016275406 | accuracy: 0.757\n",
      "\tbatch 23 | loss: 0.24400001764297485 | accuracy: 0.751\n",
      "\tbatch 24 | loss: 0.24400001764297485 | accuracy: 0.753\n",
      "\tbatch 1 | loss: 0.21899515390396118 | accuracy: 0.778\n",
      "\tbatch 2 | loss: 0.23400001227855682 | accuracy: 0.763\n",
      "\tbatch 3 | loss: 0.2335238754749298 | accuracy: 0.763\n",
      "\tbatch 4 | loss: 0.1940000057220459 | accuracy: 0.803\n",
      "\tbatch 5 | loss: 0.2109999805688858 | accuracy: 0.787\n",
      "\tbatch 6 | loss: 0.23200000822544098 | accuracy: 0.767\n",
      "\tAverage accuracy 0.7768333333333333\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.22300000488758087 | accuracy: 0.774\n",
      "\tbatch 2 | loss: 0.22200001776218414 | accuracy: 0.776\n",
      "\tbatch 3 | loss: 0.21900001168251038 | accuracy: 0.777\n",
      "\tbatch 4 | loss: 0.21800000965595245 | accuracy: 0.78\n",
      "\tbatch 5 | loss: 0.22000131011009216 | accuracy: 0.778\n",
      "\tbatch 6 | loss: 0.24300001561641693 | accuracy: 0.753\n",
      "\tbatch 7 | loss: 0.23200000822544098 | accuracy: 0.764\n",
      "\tbatch 8 | loss: 0.22500064969062805 | accuracy: 0.774\n",
      "\tbatch 9 | loss: 0.207015722990036 | accuracy: 0.789\n",
      "\tbatch 10 | loss: 0.22016790509223938 | accuracy: 0.776\n",
      "\tbatch 11 | loss: 0.23400001227855682 | accuracy: 0.761\n",
      "\tbatch 12 | loss: 0.21501126885414124 | accuracy: 0.779\n",
      "\tbatch 13 | loss: 0.24500000476837158 | accuracy: 0.751\n",
      "\tbatch 14 | loss: 0.2060001939535141 | accuracy: 0.789\n",
      "\tbatch 15 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 16 | loss: 0.20599931478500366 | accuracy: 0.789\n",
      "\tbatch 17 | loss: 0.2229989469051361 | accuracy: 0.775\n",
      "\tbatch 18 | loss: 0.24300001561641693 | accuracy: 0.755\n",
      "\tbatch 19 | loss: 0.2410000115633011 | accuracy: 0.756\n",
      "\tbatch 20 | loss: 0.22300000488758087 | accuracy: 0.775\n",
      "\tbatch 21 | loss: 0.2120000123977661 | accuracy: 0.785\n",
      "\tbatch 22 | loss: 0.19479745626449585 | accuracy: 0.8\n",
      "\tbatch 23 | loss: 0.23400001227855682 | accuracy: 0.764\n",
      "\tbatch 24 | loss: 0.22100001573562622 | accuracy: 0.776\n",
      "\tbatch 1 | loss: 0.22099420428276062 | accuracy: 0.777\n",
      "\tbatch 2 | loss: 0.21400001645088196 | accuracy: 0.779\n",
      "\tbatch 3 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 4 | loss: 0.22100001573562622 | accuracy: 0.778\n",
      "\tbatch 5 | loss: 0.22600001096725464 | accuracy: 0.773\n",
      "\tbatch 6 | loss: 0.2065729796886444 | accuracy: 0.789\n",
      "\tAverage accuracy 0.7768333333333334\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.23500001430511475 | accuracy: 0.76\n",
      "\tbatch 2 | loss: 0.21300001442432404 | accuracy: 0.782\n",
      "\tbatch 3 | loss: 0.22800131142139435 | accuracy: 0.77\n",
      "\tbatch 4 | loss: 0.21700000762939453 | accuracy: 0.776\n",
      "\tbatch 5 | loss: 0.23499898612499237 | accuracy: 0.763\n",
      "\tbatch 6 | loss: 0.22100001573562622 | accuracy: 0.776\n",
      "\tbatch 7 | loss: 0.19600000977516174 | accuracy: 0.802\n",
      "\tbatch 8 | loss: 0.23378831148147583 | accuracy: 0.761\n",
      "\tbatch 9 | loss: 0.2290000170469284 | accuracy: 0.77\n",
      "\tbatch 10 | loss: 0.21900001168251038 | accuracy: 0.779\n",
      "\tbatch 11 | loss: 0.23000000417232513 | accuracy: 0.766\n",
      "\tbatch 12 | loss: 0.22315575182437897 | accuracy: 0.773\n",
      "\tbatch 13 | loss: 0.21200016140937805 | accuracy: 0.787\n",
      "\tbatch 14 | loss: 0.23600001633167267 | accuracy: 0.761\n",
      "\tbatch 15 | loss: 0.21200595796108246 | accuracy: 0.783\n",
      "\tbatch 16 | loss: 0.2410000115633011 | accuracy: 0.757\n",
      "\tbatch 17 | loss: 0.2290000170469284 | accuracy: 0.77\n",
      "\tbatch 18 | loss: 0.2089984118938446 | accuracy: 0.789\n",
      "\tbatch 19 | loss: 0.21400001645088196 | accuracy: 0.78\n",
      "\tbatch 20 | loss: 0.2370000183582306 | accuracy: 0.758\n",
      "\tbatch 21 | loss: 0.21400001645088196 | accuracy: 0.784\n",
      "\tbatch 22 | loss: 0.23000000417232513 | accuracy: 0.769\n",
      "\tbatch 23 | loss: 0.2260008603334427 | accuracy: 0.768\n",
      "\tbatch 24 | loss: 0.20200000703334808 | accuracy: 0.796\n",
      "\tbatch 1 | loss: 0.2329932004213333 | accuracy: 0.763\n",
      "\tbatch 2 | loss: 0.21661323308944702 | accuracy: 0.779\n",
      "\tbatch 3 | loss: 0.2160000056028366 | accuracy: 0.782\n",
      "\tbatch 4 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 5 | loss: 0.2070000171661377 | accuracy: 0.79\n",
      "\tbatch 6 | loss: 0.2290000170469284 | accuracy: 0.769\n",
      "\tAverage accuracy 0.7768333333333333\n",
      "-------------------------------------\n",
      "|cos_warm, adamw|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.784000039100647 | accuracy: 0.216\n",
      "\tbatch 2 | loss: 0.7660000324249268 | accuracy: 0.234\n",
      "\tbatch 3 | loss: 0.7750000357627869 | accuracy: 0.225\n",
      "\tbatch 4 | loss: 0.7790000438690186 | accuracy: 0.221\n",
      "\tbatch 5 | loss: 0.7660000324249268 | accuracy: 0.234\n",
      "\tbatch 6 | loss: 0.7850000262260437 | accuracy: 0.215\n",
      "\tbatch 7 | loss: 0.7780000567436218 | accuracy: 0.222\n",
      "\tbatch 8 | loss: 0.7770000100135803 | accuracy: 0.223\n",
      "\tbatch 9 | loss: 0.781000018119812 | accuracy: 0.219\n",
      "\tbatch 10 | loss: 0.7880000472068787 | accuracy: 0.212\n",
      "\tbatch 11 | loss: 0.7600000500679016 | accuracy: 0.24\n",
      "\tbatch 12 | loss: 0.7760000228881836 | accuracy: 0.224\n",
      "\tbatch 13 | loss: 0.7740000486373901 | accuracy: 0.226\n",
      "\tbatch 14 | loss: 0.7880000472068787 | accuracy: 0.212\n",
      "\tbatch 15 | loss: 0.784000039100647 | accuracy: 0.216\n",
      "\tbatch 16 | loss: 0.7660000324249268 | accuracy: 0.234\n",
      "\tbatch 17 | loss: 0.7800000309944153 | accuracy: 0.22\n",
      "\tbatch 18 | loss: 0.7800000309944153 | accuracy: 0.22\n",
      "\tbatch 19 | loss: 0.7970000505447388 | accuracy: 0.203\n",
      "\tbatch 20 | loss: 0.7940000295639038 | accuracy: 0.205\n",
      "\tbatch 21 | loss: 0.7540000081062317 | accuracy: 0.246\n",
      "\tbatch 22 | loss: 0.7970000505447388 | accuracy: 0.202\n",
      "\tbatch 23 | loss: 0.7610000371932983 | accuracy: 0.239\n",
      "\tbatch 24 | loss: 0.7790000438690186 | accuracy: 0.221\n",
      "\tbatch 1 | loss: 0.8060000538825989 | accuracy: 0.194\n",
      "\tbatch 2 | loss: 0.762999415397644 | accuracy: 0.237\n",
      "\tbatch 3 | loss: 0.778184711933136 | accuracy: 0.22\n",
      "\tbatch 4 | loss: 0.7890000343322754 | accuracy: 0.211\n",
      "\tbatch 5 | loss: 0.7640000581741333 | accuracy: 0.233\n",
      "\tbatch 6 | loss: 0.7700000405311584 | accuracy: 0.229\n",
      "\tAverage accuracy 0.22066666666666668\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.7779709696769714 | accuracy: 0.222\n",
      "\tbatch 2 | loss: 0.1990000158548355 | accuracy: 0.801\n",
      "\tbatch 3 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 4 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 5 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 6 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 7 | loss: 0.2410000115633011 | accuracy: 0.759\n",
      "\tbatch 8 | loss: 0.19600000977516174 | accuracy: 0.804\n",
      "\tbatch 9 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 10 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 11 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 12 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 13 | loss: 0.26200002431869507 | accuracy: 0.738\n",
      "\tbatch 14 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 15 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 16 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 17 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 18 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 19 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 20 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 21 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 22 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 23 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 24 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 1 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 2 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 3 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 4 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 5 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 6 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 2 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 3 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 4 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 5 | loss: 0.24300001561641693 | accuracy: 0.757\n",
      "\tbatch 6 | loss: 0.20100000500679016 | accuracy: 0.799\n",
      "\tbatch 7 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 8 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 9 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 10 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 11 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 12 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 13 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 14 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 15 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 16 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 17 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 18 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 19 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 20 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 21 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 22 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 23 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 24 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 1 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 2 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 3 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 4 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 5 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 6 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 2 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 3 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 4 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 5 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 6 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 7 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 8 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 9 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 10 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 11 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 12 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 13 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 14 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 15 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 16 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tbatch 17 | loss: 0.19600000977516174 | accuracy: 0.804\n",
      "\tbatch 18 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 19 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 20 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 21 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 22 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 23 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 24 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 1 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 2 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 3 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 4 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 5 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 6 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 2 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 3 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 4 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 5 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 6 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 7 | loss: 0.25 | accuracy: 0.75\n",
      "\tbatch 8 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 9 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 10 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 11 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 12 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 13 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 14 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 15 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 16 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 17 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 18 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 19 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 20 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 21 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 22 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 23 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 24 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 1 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 2 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 3 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 4 | loss: 0.23900000751018524 | accuracy: 0.761\n",
      "\tbatch 5 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 6 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "-------------------------------------\n",
      "|cos_warm, rmsprop|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.5370003581047058 | accuracy: 0.455\n",
      "\tbatch 2 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 3 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 4 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 5 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 6 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 7 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 8 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tbatch 9 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 10 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 11 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 12 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 13 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 14 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 15 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 16 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 17 | loss: 0.1980000138282776 | accuracy: 0.802\n",
      "\tbatch 18 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 19 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 20 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 21 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 22 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 23 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 24 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 1 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tbatch 2 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 3 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 4 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 5 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 6 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 2 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 3 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 4 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 5 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 6 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 7 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 8 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 9 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 10 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 11 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 12 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 13 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 14 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 15 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 16 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 17 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 18 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 19 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 20 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 21 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 22 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 23 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 24 | loss: 0.24500000476837158 | accuracy: 0.755\n",
      "\tbatch 1 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 2 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 3 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 4 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 5 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 6 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tAverage accuracy 0.7811666666666669\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 2 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 3 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 4 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 5 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 6 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 7 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 8 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 9 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 10 | loss: 0.25 | accuracy: 0.75\n",
      "\tbatch 11 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 12 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 13 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 14 | loss: 0.19700001180171967 | accuracy: 0.803\n",
      "\tbatch 15 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 16 | loss: 0.19300000369548798 | accuracy: 0.807\n",
      "\tbatch 17 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 18 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 19 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 20 | loss: 0.24700000882148743 | accuracy: 0.753\n",
      "\tbatch 21 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tbatch 22 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 23 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 24 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 1 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 2 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 3 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 4 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 5 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 6 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tAverage accuracy 0.7811666666666666\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 2 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 3 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 4 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 5 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 6 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 7 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 8 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 9 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 10 | loss: 0.1980000138282776 | accuracy: 0.802\n",
      "\tbatch 11 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 12 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 13 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 14 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 15 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 16 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 17 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 18 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 19 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 20 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 21 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 22 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 23 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 24 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 1 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 2 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 3 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 4 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 5 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 6 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tAverage accuracy 0.7811666666666666\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 2 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 3 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 4 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 5 | loss: 0.1860000044107437 | accuracy: 0.814\n",
      "\tbatch 6 | loss: 0.24700000882148743 | accuracy: 0.753\n",
      "\tbatch 7 | loss: 0.19100001454353333 | accuracy: 0.809\n",
      "\tbatch 8 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 9 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 10 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 11 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 12 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 13 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 14 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 15 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 16 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 17 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 18 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 19 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 20 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 21 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 22 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 23 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 24 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 1 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 2 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 3 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 4 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 5 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 6 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "-------------------------------------\n",
      "|cos_warm, adagrad|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 2 | loss: 0.24900001287460327 | accuracy: 0.751\n",
      "\tbatch 3 | loss: 0.18800000846385956 | accuracy: 0.812\n",
      "\tbatch 4 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 5 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 6 | loss: 0.24300001561641693 | accuracy: 0.757\n",
      "\tbatch 7 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 8 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 9 | loss: 0.19499260187149048 | accuracy: 0.804\n",
      "\tbatch 10 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 11 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 12 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 13 | loss: 0.25 | accuracy: 0.75\n",
      "\tbatch 14 | loss: 0.1900000125169754 | accuracy: 0.81\n",
      "\tbatch 15 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 16 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 17 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 18 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 19 | loss: 0.24800001084804535 | accuracy: 0.752\n",
      "\tbatch 20 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 21 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 22 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 23 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 24 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 1 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 2 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 3 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 4 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 5 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 6 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 2 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 3 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 4 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 5 | loss: 0.2410000115633011 | accuracy: 0.759\n",
      "\tbatch 6 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 7 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 8 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 9 | loss: 0.24300001561641693 | accuracy: 0.757\n",
      "\tbatch 10 | loss: 0.18900001049041748 | accuracy: 0.811\n",
      "\tbatch 11 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 12 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 13 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 14 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 15 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 16 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 17 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 18 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 19 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 20 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 21 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 22 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 23 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 24 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 1 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 2 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 3 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 4 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 5 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 6 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.19600000977516174 | accuracy: 0.804\n",
      "\tbatch 2 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 3 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 4 | loss: 0.2410000115633011 | accuracy: 0.759\n",
      "\tbatch 5 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 6 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 7 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tbatch 8 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 9 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 10 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 11 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 12 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 13 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 14 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 15 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tbatch 16 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 17 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 18 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 19 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 20 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 21 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 22 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 23 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 24 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 1 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 2 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 3 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 4 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 5 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 6 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tAverage accuracy 0.7811666666666666\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 2 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 3 | loss: 0.2410000115633011 | accuracy: 0.759\n",
      "\tbatch 4 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 5 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 6 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 7 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 8 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 9 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 10 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 11 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 12 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 13 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 14 | loss: 0.20100000500679016 | accuracy: 0.799\n",
      "\tbatch 15 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 16 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 17 | loss: 0.25200000405311584 | accuracy: 0.748\n",
      "\tbatch 18 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 19 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 20 | loss: 0.24400001764297485 | accuracy: 0.756\n",
      "\tbatch 21 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 22 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 23 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 24 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 1 | loss: 0.23900000751018524 | accuracy: 0.761\n",
      "\tbatch 2 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 3 | loss: 0.19600000977516174 | accuracy: 0.804\n",
      "\tbatch 4 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 5 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 6 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tAverage accuracy 0.7811666666666666\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 2 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 3 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 4 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 5 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 6 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 7 | loss: 0.24800001084804535 | accuracy: 0.752\n",
      "\tbatch 8 | loss: 0.1980000138282776 | accuracy: 0.802\n",
      "\tbatch 9 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 10 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 11 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 12 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 13 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tbatch 14 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 15 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 16 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 17 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 18 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 19 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 20 | loss: 0.24900001287460327 | accuracy: 0.751\n",
      "\tbatch 21 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 22 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 23 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 24 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 1 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 2 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 3 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 4 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 5 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 6 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "-------------------------------------\n",
      "|plateau, adamw|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.7509990334510803 | accuracy: 0.238\n",
      "\tbatch 2 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 3 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 4 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 5 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 6 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 7 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 8 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 9 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 10 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 11 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 12 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 13 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 14 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 15 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 16 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 17 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 18 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 19 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 20 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 21 | loss: 0.24400001764297485 | accuracy: 0.756\n",
      "\tbatch 22 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 23 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 24 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 1 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 2 | loss: 0.19600000977516174 | accuracy: 0.804\n",
      "\tbatch 3 | loss: 0.24700000882148743 | accuracy: 0.753\n",
      "\tbatch 4 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 5 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 6 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 2 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 3 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 4 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 5 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 6 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 7 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 8 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 9 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 10 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 11 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 12 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 13 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 14 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 15 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 16 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tbatch 17 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 18 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 19 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 20 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 21 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 22 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 23 | loss: 0.20100000500679016 | accuracy: 0.799\n",
      "\tbatch 24 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 1 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 2 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 3 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 4 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 5 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 6 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 2 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 3 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 4 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 5 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 6 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 7 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 8 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 9 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 10 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 11 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 12 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 13 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 14 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 15 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 16 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 17 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 18 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 19 | loss: 0.24500000476837158 | accuracy: 0.755\n",
      "\tbatch 20 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 21 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 22 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 23 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 24 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 1 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 2 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 3 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 4 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 5 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 6 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.2410000115633011 | accuracy: 0.759\n",
      "\tbatch 2 | loss: 0.1980000138282776 | accuracy: 0.802\n",
      "\tbatch 3 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 4 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 5 | loss: 0.24300001561641693 | accuracy: 0.757\n",
      "\tbatch 6 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 7 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 8 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 9 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 10 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 11 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 12 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 13 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 14 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 15 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 16 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 17 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 18 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 19 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 20 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 21 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 22 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 23 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 24 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 1 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 2 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 3 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 4 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 5 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tbatch 6 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tAverage accuracy 0.7811666666666666\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.1980000138282776 | accuracy: 0.802\n",
      "\tbatch 2 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 3 | loss: 0.2540000081062317 | accuracy: 0.746\n",
      "\tbatch 4 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 5 | loss: 0.1980000138282776 | accuracy: 0.802\n",
      "\tbatch 6 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 7 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 8 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 9 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 10 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 11 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 12 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 13 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 14 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 15 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tbatch 16 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 17 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tbatch 18 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 19 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 20 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 21 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 22 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 23 | loss: 0.1980000138282776 | accuracy: 0.802\n",
      "\tbatch 24 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 1 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 2 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 3 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 4 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 5 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 6 | loss: 0.1980000138282776 | accuracy: 0.802\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "-------------------------------------\n",
      "|plateau, rmsprop|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.6025660634040833 | accuracy: 0.368\n",
      "\tbatch 2 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tbatch 3 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 4 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 5 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 6 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 7 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 8 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 9 | loss: 0.26200002431869507 | accuracy: 0.738\n",
      "\tbatch 10 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 11 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 12 | loss: 0.24800001084804535 | accuracy: 0.752\n",
      "\tbatch 13 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 14 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 15 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 16 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 17 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 18 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 19 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 20 | loss: 0.19300000369548798 | accuracy: 0.807\n",
      "\tbatch 21 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 22 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 23 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 24 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 1 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 2 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 3 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 4 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 5 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 6 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 2 | loss: 0.25300002098083496 | accuracy: 0.747\n",
      "\tbatch 3 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 4 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 5 | loss: 0.2410000115633011 | accuracy: 0.759\n",
      "\tbatch 6 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 7 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 8 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 9 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 10 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 11 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 12 | loss: 0.20100000500679016 | accuracy: 0.799\n",
      "\tbatch 13 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 14 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 15 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 16 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 17 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 18 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 19 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 20 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 21 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 22 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 23 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 24 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 1 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 2 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 3 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 4 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 5 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 6 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.1850000023841858 | accuracy: 0.815\n",
      "\tbatch 2 | loss: 0.2540000081062317 | accuracy: 0.746\n",
      "\tbatch 3 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 4 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 5 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 6 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 7 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 8 | loss: 0.26500001549720764 | accuracy: 0.735\n",
      "\tbatch 9 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 10 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 11 | loss: 0.23900000751018524 | accuracy: 0.761\n",
      "\tbatch 12 | loss: 0.20600001513957977 | accuracy: 0.794\n",
      "\tbatch 13 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 14 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 15 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 16 | loss: 0.23600001633167267 | accuracy: 0.764\n",
      "\tbatch 17 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 18 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 19 | loss: 0.1990000158548355 | accuracy: 0.801\n",
      "\tbatch 20 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 21 | loss: 0.25200000405311584 | accuracy: 0.748\n",
      "\tbatch 22 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 23 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 24 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 1 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 2 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 3 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 4 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 5 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 6 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tAverage accuracy 0.7811666666666666\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 2 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 3 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 4 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 5 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 6 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 7 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 8 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 9 | loss: 0.19300000369548798 | accuracy: 0.807\n",
      "\tbatch 10 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 11 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 12 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 13 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 14 | loss: 0.1990000158548355 | accuracy: 0.801\n",
      "\tbatch 15 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 16 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 17 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 18 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 19 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 20 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 21 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 22 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 23 | loss: 0.242000013589859 | accuracy: 0.758\n",
      "\tbatch 24 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 1 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 2 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 3 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 4 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 5 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 6 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tAverage accuracy 0.7811666666666666\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 2 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 3 | loss: 0.2670000195503235 | accuracy: 0.733\n",
      "\tbatch 4 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 5 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 6 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 7 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 8 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 9 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 10 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 11 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 12 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 13 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 14 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 15 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 16 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 17 | loss: 0.1990000158548355 | accuracy: 0.801\n",
      "\tbatch 18 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 19 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 20 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 21 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 22 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 23 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tbatch 24 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 1 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 2 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 3 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 4 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 5 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 6 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "-------------------------------------\n",
      "|plateau, adagrad|\n",
      "Epoch 1\n",
      "\tbatch 1 | loss: 0.7710000276565552 | accuracy: 0.229\n",
      "\tbatch 2 | loss: 0.7450000643730164 | accuracy: 0.255\n",
      "\tbatch 3 | loss: 0.7930000424385071 | accuracy: 0.207\n",
      "\tbatch 4 | loss: 0.7780000567436218 | accuracy: 0.221\n",
      "\tbatch 5 | loss: 0.7600000500679016 | accuracy: 0.24\n",
      "\tbatch 6 | loss: 0.7880000472068787 | accuracy: 0.212\n",
      "\tbatch 7 | loss: 0.7830000519752502 | accuracy: 0.217\n",
      "\tbatch 8 | loss: 0.7600000500679016 | accuracy: 0.239\n",
      "\tbatch 9 | loss: 0.7830000519752502 | accuracy: 0.217\n",
      "\tbatch 10 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 11 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 12 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 13 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 14 | loss: 0.23400001227855682 | accuracy: 0.766\n",
      "\tbatch 15 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 16 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 17 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 18 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 19 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 20 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 21 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 22 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 23 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 24 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 1 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 2 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 3 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 4 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 5 | loss: 0.2110000103712082 | accuracy: 0.789\n",
      "\tbatch 6 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tAverage accuracy 0.7811666666666666\n",
      "Epoch 2\n",
      "\tbatch 1 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 2 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 3 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 4 | loss: 0.2460000067949295 | accuracy: 0.754\n",
      "\tbatch 5 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 6 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 7 | loss: 0.23900000751018524 | accuracy: 0.761\n",
      "\tbatch 8 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 9 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 10 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 11 | loss: 0.20100000500679016 | accuracy: 0.799\n",
      "\tbatch 12 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 13 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 14 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 15 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 16 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 17 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 18 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 19 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 20 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 21 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 22 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 23 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 24 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 1 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 2 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 3 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 4 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 5 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 6 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 3\n",
      "\tbatch 1 | loss: 0.25200000405311584 | accuracy: 0.748\n",
      "\tbatch 2 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 3 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 4 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 5 | loss: 0.24900001287460327 | accuracy: 0.751\n",
      "\tbatch 6 | loss: 0.24700000882148743 | accuracy: 0.753\n",
      "\tbatch 7 | loss: 0.1940000057220459 | accuracy: 0.806\n",
      "\tbatch 8 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 9 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 10 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 11 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 12 | loss: 0.2150000035762787 | accuracy: 0.785\n",
      "\tbatch 13 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 14 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 15 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 16 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 17 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 18 | loss: 0.20400001108646393 | accuracy: 0.796\n",
      "\tbatch 19 | loss: 0.22100001573562622 | accuracy: 0.779\n",
      "\tbatch 20 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 21 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 22 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 23 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 24 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 1 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 2 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 3 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 4 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 5 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 6 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 4\n",
      "\tbatch 1 | loss: 0.22600001096725464 | accuracy: 0.774\n",
      "\tbatch 2 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 3 | loss: 0.21900001168251038 | accuracy: 0.781\n",
      "\tbatch 4 | loss: 0.22700001299381256 | accuracy: 0.773\n",
      "\tbatch 5 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 6 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 7 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 8 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 9 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 10 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 11 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 12 | loss: 0.24000000953674316 | accuracy: 0.76\n",
      "\tbatch 13 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 14 | loss: 0.21400001645088196 | accuracy: 0.786\n",
      "\tbatch 15 | loss: 0.19300000369548798 | accuracy: 0.807\n",
      "\tbatch 16 | loss: 0.22300000488758087 | accuracy: 0.777\n",
      "\tbatch 17 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 18 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 19 | loss: 0.20200000703334808 | accuracy: 0.798\n",
      "\tbatch 20 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tbatch 21 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 22 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 23 | loss: 0.2240000069141388 | accuracy: 0.776\n",
      "\tbatch 24 | loss: 0.24500000476837158 | accuracy: 0.755\n",
      "\tbatch 1 | loss: 0.21300001442432404 | accuracy: 0.787\n",
      "\tbatch 2 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 3 | loss: 0.18900001049041748 | accuracy: 0.811\n",
      "\tbatch 4 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 5 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 6 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tAverage accuracy 0.7811666666666667\n",
      "Epoch 5\n",
      "\tbatch 1 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 2 | loss: 0.2330000102519989 | accuracy: 0.767\n",
      "\tbatch 3 | loss: 0.21800000965595245 | accuracy: 0.782\n",
      "\tbatch 4 | loss: 0.24900001287460327 | accuracy: 0.751\n",
      "\tbatch 5 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 6 | loss: 0.2200000137090683 | accuracy: 0.78\n",
      "\tbatch 7 | loss: 0.2370000183582306 | accuracy: 0.763\n",
      "\tbatch 8 | loss: 0.23500001430511475 | accuracy: 0.765\n",
      "\tbatch 9 | loss: 0.23800000548362732 | accuracy: 0.762\n",
      "\tbatch 10 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 11 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 12 | loss: 0.2120000123977661 | accuracy: 0.788\n",
      "\tbatch 13 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 14 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 15 | loss: 0.23100000619888306 | accuracy: 0.769\n",
      "\tbatch 16 | loss: 0.22500000894069672 | accuracy: 0.775\n",
      "\tbatch 17 | loss: 0.22200001776218414 | accuracy: 0.778\n",
      "\tbatch 18 | loss: 0.21000000834465027 | accuracy: 0.79\n",
      "\tbatch 19 | loss: 0.203000009059906 | accuracy: 0.797\n",
      "\tbatch 20 | loss: 0.2290000170469284 | accuracy: 0.771\n",
      "\tbatch 21 | loss: 0.20800000429153442 | accuracy: 0.792\n",
      "\tbatch 22 | loss: 0.21700000762939453 | accuracy: 0.783\n",
      "\tbatch 23 | loss: 0.20500001311302185 | accuracy: 0.795\n",
      "\tbatch 24 | loss: 0.20900000631809235 | accuracy: 0.791\n",
      "\tbatch 1 | loss: 0.23000000417232513 | accuracy: 0.77\n",
      "\tbatch 2 | loss: 0.22800001502037048 | accuracy: 0.772\n",
      "\tbatch 3 | loss: 0.23200000822544098 | accuracy: 0.768\n",
      "\tbatch 4 | loss: 0.20000000298023224 | accuracy: 0.8\n",
      "\tbatch 5 | loss: 0.2070000171661377 | accuracy: 0.793\n",
      "\tbatch 6 | loss: 0.2160000056028366 | accuracy: 0.784\n",
      "\tAverage accuracy 0.7811666666666667\n"
     ]
    }
   ],
   "source": [
    "df = credit.train(\n",
    "    result_csv = \"test.csv\", \n",
    "    optimizers = optimizers,\n",
    "    schedulers = schedulers,\n",
    "    epochs = 5,\n",
    "    batch_size = 1000,\n",
    "    device = \"cuda\",\n",
    "    loss_func = torch.nn.MSELoss\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"distilbert/distilroberta-base\"\n",
    "\n",
    "pii = PII()\n",
    "pii.load_tokenizer(model_path)\n",
    "pii.prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    \"adamw\": (torch.optim.AdamW, {\"lr\": 2e-5}),\n",
    "    \"rmsprop\": (torch.optim.RMSprop, {\"lr\": 2e-5, \"momentum\": 0}),\n",
    "    \"adagrad\": (torch.optim.Adagrad, {\"lr\": 3e-5}),\n",
    "}\n",
    "\n",
    "schedulers = {\n",
    "    \"linear\": {\"num_warmup_steps\": 0},\n",
    "    \"cosine\": {\"num_warmup_steps\": 0},\n",
    "    \"polynomial\": {\"num_warmup_steps\": 0, \"power\": 2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Optimizer: adamw | Scheduler: linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.13120447099208832, 'eval_precision': 0.7934772788869816, 'eval_recall': 0.8295239894219871, 'eval_f1': 0.8111003370734635, 'eval_accuracy': 0.9619373446657052, 'eval_runtime': 3.9377, 'eval_samples_per_second': 825.357, 'eval_steps_per_second': 5.587, 'epoch': 1.0}\n",
      "{'eval_loss': 0.06966577470302582, 'eval_precision': 0.9029126213592233, 'eval_recall': 0.9222704948998867, 'eval_f1': 0.9124889034247536, 'eval_accuracy': 0.980040501979074, 'eval_runtime': 4.2822, 'eval_samples_per_second': 758.952, 'eval_steps_per_second': 5.138, 'epoch': 2.0}\n",
      "{'eval_loss': 0.05863739550113678, 'eval_precision': 0.9199440820130476, 'eval_recall': 0.9322818284850775, 'eval_f1': 0.9260718641523594, 'eval_accuracy': 0.9825565340124575, 'eval_runtime': 4.0709, 'eval_samples_per_second': 798.356, 'eval_steps_per_second': 5.404, 'epoch': 3.0}\n",
      "{'eval_loss': 0.053025200963020325, 'eval_precision': 0.9270378287944976, 'eval_recall': 0.9420098224404987, 'eval_f1': 0.9344638590902703, 'eval_accuracy': 0.9845509496486761, 'eval_runtime': 3.9832, 'eval_samples_per_second': 815.918, 'eval_steps_per_second': 5.523, 'epoch': 4.0}\n",
      "{'eval_loss': 0.05383315682411194, 'eval_precision': 0.9300269842746813, 'eval_recall': 0.9439931998488855, 'eval_f1': 0.9369580501523318, 'eval_accuracy': 0.9851492743395416, 'eval_runtime': 4.5547, 'eval_samples_per_second': 713.549, 'eval_steps_per_second': 4.83, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory test//adamw_linear\\checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1533, 'grad_norm': 0.6746379733085632, 'learning_rate': 9.316239316239318e-06, 'epoch': 5.32}\n",
      "{'eval_loss': 0.05085839331150055, 'eval_precision': 0.9328066914498141, 'eval_recall': 0.9479599546656592, 'eval_f1': 0.940322278433577, 'eval_accuracy': 0.9856402074192262, 'eval_runtime': 3.9764, 'eval_samples_per_second': 817.332, 'eval_steps_per_second': 5.533, 'epoch': 6.0}\n",
      "{'eval_loss': 0.05173797905445099, 'eval_precision': 0.9363069187075147, 'eval_recall': 0.9496599924442766, 'eval_f1': 0.9429361841796784, 'eval_accuracy': 0.9862078487926115, 'eval_runtime': 3.98, 'eval_samples_per_second': 816.583, 'eval_steps_per_second': 5.528, 'epoch': 7.0}\n",
      "{'eval_loss': 0.05042613670229912, 'eval_precision': 0.9377736376339078, 'eval_recall': 0.9507933509633547, 'eval_f1': 0.9442386155794213, 'eval_accuracy': 0.9864686569911939, 'eval_runtime': 4.1097, 'eval_samples_per_second': 790.819, 'eval_steps_per_second': 5.353, 'epoch': 8.0}\n",
      "{'eval_loss': 0.05087592825293541, 'eval_precision': 0.9396792839828454, 'eval_recall': 0.951926709482433, 'eval_f1': 0.9457633480341561, 'eval_accuracy': 0.9866680985548157, 'eval_runtime': 4.0244, 'eval_samples_per_second': 807.573, 'eval_steps_per_second': 5.467, 'epoch': 9.0}\n",
      "{'eval_loss': 0.050687626004219055, 'eval_precision': 0.9397781299524565, 'eval_recall': 0.952115602568946, 'eval_f1': 0.945906638517476, 'eval_accuracy': 0.9865913902611151, 'eval_runtime': 4.128, 'eval_samples_per_second': 787.305, 'eval_steps_per_second': 5.329, 'epoch': 10.0}\n",
      "{'train_runtime': 197.5167, 'train_samples_per_second': 710.876, 'train_steps_per_second': 4.759, 'train_loss': 0.09450162623790985, 'epoch': 10.0}\n",
      "----------------------------\n",
      "Optimizer: adamw | Scheduler: cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1332087516784668, 'eval_precision': 0.7909131803868646, 'eval_recall': 0.8302795617680393, 'eval_f1': 0.8101184168087361, 'eval_accuracy': 0.9617072197846032, 'eval_runtime': 4.1014, 'eval_samples_per_second': 792.405, 'eval_steps_per_second': 5.364, 'epoch': 1.0}\n",
      "{'eval_loss': 0.07017938047647476, 'eval_precision': 0.9055045019957301, 'eval_recall': 0.9213260294673215, 'eval_f1': 0.9133467534291466, 'eval_accuracy': 0.9795495688993894, 'eval_runtime': 4.0259, 'eval_samples_per_second': 807.264, 'eval_steps_per_second': 5.465, 'epoch': 2.0}\n",
      "{'eval_loss': 0.05652053654193878, 'eval_precision': 0.9211335881420714, 'eval_recall': 0.9332262939176427, 'eval_f1': 0.9271405113769646, 'eval_accuracy': 0.9828940505047405, 'eval_runtime': 4.0496, 'eval_samples_per_second': 802.556, 'eval_steps_per_second': 5.433, 'epoch': 3.0}\n",
      "{'eval_loss': 0.052355531603097916, 'eval_precision': 0.9326932040645101, 'eval_recall': 0.9449376652814507, 'eval_f1': 0.9387755102040817, 'eval_accuracy': 0.9852259826332423, 'eval_runtime': 4.1935, 'eval_samples_per_second': 775.005, 'eval_steps_per_second': 5.246, 'epoch': 4.0}\n",
      "{'eval_loss': 0.05328955873847008, 'eval_precision': 0.9332276415182318, 'eval_recall': 0.9451265583679638, 'eval_f1': 0.939139411571489, 'eval_accuracy': 0.9854407658556044, 'eval_runtime': 4.0194, 'eval_samples_per_second': 808.568, 'eval_steps_per_second': 5.473, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory test//adamw_cosine\\checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.154, 'grad_norm': 0.9108741283416748, 'learning_rate': 8.928015042125523e-06, 'epoch': 5.32}\n",
      "{'eval_loss': 0.05079275369644165, 'eval_precision': 0.9350637268583124, 'eval_recall': 0.9492822062712505, 'eval_f1': 0.942119323241318, 'eval_accuracy': 0.9859623822527692, 'eval_runtime': 4.0458, 'eval_samples_per_second': 803.293, 'eval_steps_per_second': 5.438, 'epoch': 6.0}\n",
      "{'eval_loss': 0.0516202487051487, 'eval_precision': 0.9369235069412094, 'eval_recall': 0.9497544389875331, 'eval_f1': 0.9432953426199522, 'eval_accuracy': 0.9862538737688319, 'eval_runtime': 3.974, 'eval_samples_per_second': 817.823, 'eval_steps_per_second': 5.536, 'epoch': 7.0}\n",
      "{'eval_loss': 0.050755225121974945, 'eval_precision': 0.938995995156934, 'eval_recall': 0.9522100491122025, 'eval_f1': 0.9455568581477141, 'eval_accuracy': 0.9866680985548157, 'eval_runtime': 4.0091, 'eval_samples_per_second': 810.658, 'eval_steps_per_second': 5.488, 'epoch': 8.0}\n",
      "{'eval_loss': 0.051185496151447296, 'eval_precision': 0.9372614725868007, 'eval_recall': 0.9509822440498678, 'eval_f1': 0.9440720078758615, 'eval_accuracy': 0.9864993403086741, 'eval_runtime': 4.0178, 'eval_samples_per_second': 808.894, 'eval_steps_per_second': 5.476, 'epoch': 9.0}\n",
      "{'eval_loss': 0.051049184054136276, 'eval_precision': 0.937534909700242, 'eval_recall': 0.9511711371363808, 'eval_f1': 0.9443037974683545, 'eval_accuracy': 0.9865300236261545, 'eval_runtime': 4.4601, 'eval_samples_per_second': 728.683, 'eval_steps_per_second': 4.933, 'epoch': 10.0}\n",
      "{'train_runtime': 197.7807, 'train_samples_per_second': 709.928, 'train_steps_per_second': 4.753, 'train_loss': 0.09450923026876247, 'epoch': 10.0}\n",
      "----------------------------\n",
      "Optimizer: adamw | Scheduler: polynomial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.14225637912750244, 'eval_precision': 0.7803478572709341, 'eval_recall': 0.8220627125047223, 'eval_f1': 0.8006623125747402, 'eval_accuracy': 0.9595287042435028, 'eval_runtime': 4.053, 'eval_samples_per_second': 801.87, 'eval_steps_per_second': 5.428, 'epoch': 1.0}\n",
      "{'eval_loss': 0.07827768474817276, 'eval_precision': 0.893463810930576, 'eval_recall': 0.9140536456365697, 'eval_f1': 0.903641456582633, 'eval_accuracy': 0.9774631033107299, 'eval_runtime': 4.0544, 'eval_samples_per_second': 801.603, 'eval_steps_per_second': 5.426, 'epoch': 2.0}\n",
      "{'eval_loss': 0.06198497116565704, 'eval_precision': 0.9135401188707281, 'eval_recall': 0.9290706460143558, 'eval_f1': 0.9212399325716426, 'eval_accuracy': 0.9816667178055292, 'eval_runtime': 4.0421, 'eval_samples_per_second': 804.032, 'eval_steps_per_second': 5.443, 'epoch': 3.0}\n",
      "{'eval_loss': 0.05753719434142113, 'eval_precision': 0.9223841797418996, 'eval_recall': 0.9383264072534945, 'eval_f1': 0.9302869984549837, 'eval_accuracy': 0.983691816759228, 'eval_runtime': 4.0991, 'eval_samples_per_second': 792.857, 'eval_steps_per_second': 5.367, 'epoch': 4.0}\n",
      "{'eval_loss': 0.055312629789114, 'eval_precision': 0.924814126394052, 'eval_recall': 0.9398375519455988, 'eval_f1': 0.932265317594154, 'eval_accuracy': 0.9841980914976527, 'eval_runtime': 4.0054, 'eval_samples_per_second': 811.402, 'eval_steps_per_second': 5.493, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory test//adamw_polynomial\\checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1641, 'grad_norm': 1.2281861305236816, 'learning_rate': 4.4179176711228e-06, 'epoch': 5.32}\n",
      "{'eval_loss': 0.05387108400464058, 'eval_precision': 0.9279203869047619, 'eval_recall': 0.9422931620702683, 'eval_f1': 0.9350515463917526, 'eval_accuracy': 0.9845816329661563, 'eval_runtime': 4.1712, 'eval_samples_per_second': 779.156, 'eval_steps_per_second': 5.274, 'epoch': 6.0}\n",
      "{'eval_loss': 0.053280774503946304, 'eval_precision': 0.9294806280776735, 'eval_recall': 0.9448432187381942, 'eval_f1': 0.9370989649196759, 'eval_accuracy': 0.9851646159982818, 'eval_runtime': 4.0251, 'eval_samples_per_second': 807.435, 'eval_steps_per_second': 5.466, 'epoch': 7.0}\n",
      "{'eval_loss': 0.053525324910879135, 'eval_precision': 0.9301914854062093, 'eval_recall': 0.9451265583679638, 'eval_f1': 0.9375995502670289, 'eval_accuracy': 0.985195299315762, 'eval_runtime': 4.1106, 'eval_samples_per_second': 790.644, 'eval_steps_per_second': 5.352, 'epoch': 8.0}\n",
      "{'eval_loss': 0.053594380617141724, 'eval_precision': 0.9284918276374443, 'eval_recall': 0.9442765394786551, 'eval_f1': 0.9363176624836111, 'eval_accuracy': 0.9849344911171796, 'eval_runtime': 4.0445, 'eval_samples_per_second': 803.551, 'eval_steps_per_second': 5.439, 'epoch': 9.0}\n",
      "{'eval_loss': 0.05337562412023544, 'eval_precision': 0.928597957288765, 'eval_recall': 0.9445598791084246, 'eval_f1': 0.9365109092611668, 'eval_accuracy': 0.9850265410696204, 'eval_runtime': 4.1882, 'eval_samples_per_second': 775.992, 'eval_steps_per_second': 5.253, 'epoch': 10.0}\n",
      "{'train_runtime': 197.0933, 'train_samples_per_second': 712.404, 'train_steps_per_second': 4.769, 'train_loss': 0.10623558125597365, 'epoch': 10.0}\n",
      "----------------------------\n",
      "Optimizer: rmsprop | Scheduler: linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07745960354804993, 'eval_precision': 0.8957043879907621, 'eval_recall': 0.915753683415187, 'eval_f1': 0.9056180824732639, 'eval_accuracy': 0.9775398116044307, 'eval_runtime': 3.9849, 'eval_samples_per_second': 815.583, 'eval_steps_per_second': 5.521, 'epoch': 1.0}\n",
      "{'eval_loss': 0.056669652462005615, 'eval_precision': 0.9287246944677675, 'eval_recall': 0.9402153381186249, 'eval_f1': 0.9344346928239545, 'eval_accuracy': 0.9838298916878893, 'eval_runtime': 4.6169, 'eval_samples_per_second': 703.941, 'eval_steps_per_second': 4.765, 'epoch': 2.0}\n",
      "{'eval_loss': 0.052368924021720886, 'eval_precision': 0.9327488107452663, 'eval_recall': 0.9444654325651681, 'eval_f1': 0.9385705570416256, 'eval_accuracy': 0.9847964161885183, 'eval_runtime': 4.0259, 'eval_samples_per_second': 807.27, 'eval_steps_per_second': 5.465, 'epoch': 3.0}\n",
      "{'eval_loss': 0.05050984025001526, 'eval_precision': 0.9361364907700913, 'eval_recall': 0.9483377408386853, 'eval_f1': 0.9421976165900348, 'eval_accuracy': 0.9857015740541868, 'eval_runtime': 4.0027, 'eval_samples_per_second': 811.959, 'eval_steps_per_second': 5.496, 'epoch': 4.0}\n",
      "{'eval_loss': 0.050899818539619446, 'eval_precision': 0.9377798507462687, 'eval_recall': 0.9494710993577635, 'eval_f1': 0.9435892622489207, 'eval_accuracy': 0.9862078487926115, 'eval_runtime': 4.0987, 'eval_samples_per_second': 792.935, 'eval_steps_per_second': 5.368, 'epoch': 5.0}\n",
      "{'loss': 0.0879, 'grad_norm': 0.5104814171791077, 'learning_rate': 9.316239316239318e-06, 'epoch': 5.32}\n",
      "{'eval_loss': 0.050242893397808075, 'eval_precision': 0.9373370577281191, 'eval_recall': 0.9507933509633547, 'eval_f1': 0.9440172543135784, 'eval_accuracy': 0.9863305820625325, 'eval_runtime': 4.0096, 'eval_samples_per_second': 810.562, 'eval_steps_per_second': 5.487, 'epoch': 6.0}\n",
      "{'eval_loss': 0.05059710144996643, 'eval_precision': 0.940160567587752, 'eval_recall': 0.9511711371363808, 'eval_f1': 0.9456338028169013, 'eval_accuracy': 0.9864993403086741, 'eval_runtime': 3.9749, 'eval_samples_per_second': 817.631, 'eval_steps_per_second': 5.535, 'epoch': 7.0}\n",
      "{'eval_loss': 0.049395009875297546, 'eval_precision': 0.943145689171498, 'eval_recall': 0.9525878352852286, 'eval_f1': 0.9478432478150549, 'eval_accuracy': 0.9871590316345004, 'eval_runtime': 3.9536, 'eval_samples_per_second': 822.033, 'eval_steps_per_second': 5.565, 'epoch': 8.0}\n",
      "{'eval_loss': 0.05000379681587219, 'eval_precision': 0.9423256683492242, 'eval_recall': 0.952115602568946, 'eval_f1': 0.9471953396598704, 'eval_accuracy': 0.9869902733883588, 'eval_runtime': 3.9925, 'eval_samples_per_second': 814.021, 'eval_steps_per_second': 5.51, 'epoch': 9.0}\n",
      "{'eval_loss': 0.0499861016869545, 'eval_precision': 0.940468414668284, 'eval_recall': 0.951926709482433, 'eval_f1': 0.9461628725651257, 'eval_accuracy': 0.9869442484121383, 'eval_runtime': 3.9549, 'eval_samples_per_second': 821.772, 'eval_steps_per_second': 5.563, 'epoch': 10.0}\n",
      "{'train_runtime': 193.0809, 'train_samples_per_second': 727.208, 'train_steps_per_second': 4.868, 'train_loss': 0.056995732733543886, 'epoch': 10.0}\n",
      "----------------------------\n",
      "Optimizer: rmsprop | Scheduler: cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07774508744478226, 'eval_precision': 0.8958660871173587, 'eval_recall': 0.9149036645258783, 'eval_f1': 0.9052847997757114, 'eval_accuracy': 0.9776625448743518, 'eval_runtime': 3.9675, 'eval_samples_per_second': 819.158, 'eval_steps_per_second': 5.545, 'epoch': 1.0}\n",
      "{'eval_loss': 0.05681734159588814, 'eval_precision': 0.9273862788963461, 'eval_recall': 0.9396486588590858, 'eval_f1': 0.933477200225183, 'eval_accuracy': 0.9836764751004878, 'eval_runtime': 3.9253, 'eval_samples_per_second': 827.964, 'eval_steps_per_second': 5.605, 'epoch': 2.0}\n",
      "{'eval_loss': 0.05257377773523331, 'eval_precision': 0.9325382035035408, 'eval_recall': 0.9452210049112203, 'eval_f1': 0.9388367729831144, 'eval_accuracy': 0.9850572243871007, 'eval_runtime': 4.0122, 'eval_samples_per_second': 810.02, 'eval_steps_per_second': 5.483, 'epoch': 3.0}\n",
      "{'eval_loss': 0.050495512783527374, 'eval_precision': 0.9353396068200875, 'eval_recall': 0.9481488477521722, 'eval_f1': 0.9417006707002485, 'eval_accuracy': 0.9856402074192262, 'eval_runtime': 4.1246, 'eval_samples_per_second': 787.953, 'eval_steps_per_second': 5.334, 'epoch': 4.0}\n",
      "{'eval_loss': 0.050735656172037125, 'eval_precision': 0.9380076556810756, 'eval_recall': 0.9489044200982244, 'eval_f1': 0.9434245739236585, 'eval_accuracy': 0.9863305820625325, 'eval_runtime': 4.1452, 'eval_samples_per_second': 784.033, 'eval_steps_per_second': 5.307, 'epoch': 5.0}\n",
      "{'loss': 0.0863, 'grad_norm': 0.49107757210731506, 'learning_rate': 8.928015042125523e-06, 'epoch': 5.32}\n",
      "{'eval_loss': 0.051185838878154755, 'eval_precision': 0.9357781087118392, 'eval_recall': 0.94956554590102, 'eval_f1': 0.942621413838365, 'eval_accuracy': 0.9860390905464699, 'eval_runtime': 3.9688, 'eval_samples_per_second': 818.88, 'eval_steps_per_second': 5.543, 'epoch': 6.0}\n",
      "{'eval_loss': 0.051488060504198074, 'eval_precision': 0.9386898096304591, 'eval_recall': 0.9500377786173027, 'eval_f1': 0.9443297033420953, 'eval_accuracy': 0.9864072903562333, 'eval_runtime': 4.0495, 'eval_samples_per_second': 802.574, 'eval_steps_per_second': 5.433, 'epoch': 7.0}\n",
      "{'eval_loss': 0.049723632633686066, 'eval_precision': 0.9420777279521674, 'eval_recall': 0.9523989421987156, 'eval_f1': 0.9472102198008642, 'eval_accuracy': 0.9870516400233194, 'eval_runtime': 3.9905, 'eval_samples_per_second': 814.44, 'eval_steps_per_second': 5.513, 'epoch': 8.0}\n",
      "{'eval_loss': 0.050006717443466187, 'eval_precision': 0.9413138958975796, 'eval_recall': 0.9513600302228938, 'eval_f1': 0.9463103010944619, 'eval_accuracy': 0.9868675401184376, 'eval_runtime': 3.9592, 'eval_samples_per_second': 820.872, 'eval_steps_per_second': 5.557, 'epoch': 9.0}\n",
      "{'eval_loss': 0.04997755214571953, 'eval_precision': 0.9410390581199776, 'eval_recall': 0.9511711371363808, 'eval_f1': 0.9460779708783467, 'eval_accuracy': 0.986806173483477, 'eval_runtime': 4.0146, 'eval_samples_per_second': 809.552, 'eval_steps_per_second': 5.48, 'epoch': 10.0}\n",
      "{'train_runtime': 193.2059, 'train_samples_per_second': 726.738, 'train_steps_per_second': 4.865, 'train_loss': 0.055552152877158305, 'epoch': 10.0}\n",
      "----------------------------\n",
      "Optimizer: rmsprop | Scheduler: polynomial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.07879018783569336, 'eval_precision': 0.8937309574369864, 'eval_recall': 0.9142425387230827, 'eval_f1': 0.9038703954432981, 'eval_accuracy': 0.9771102451597067, 'eval_runtime': 4.0155, 'eval_samples_per_second': 809.358, 'eval_steps_per_second': 5.479, 'epoch': 1.0}\n",
      "{'eval_loss': 0.058572858572006226, 'eval_precision': 0.9262126865671642, 'eval_recall': 0.9377597279939555, 'eval_f1': 0.9319504411488643, 'eval_accuracy': 0.9831702003620632, 'eval_runtime': 4.0321, 'eval_samples_per_second': 806.035, 'eval_steps_per_second': 5.456, 'epoch': 2.0}\n",
      "{'eval_loss': 0.053742073476314545, 'eval_precision': 0.928604672810202, 'eval_recall': 0.9421987155270117, 'eval_f1': 0.9353523041582673, 'eval_accuracy': 0.9842747997913535, 'eval_runtime': 4.1321, 'eval_samples_per_second': 786.522, 'eval_steps_per_second': 5.324, 'epoch': 3.0}\n",
      "{'eval_loss': 0.05085025727748871, 'eval_precision': 0.9336872496973083, 'eval_recall': 0.946826596146581, 'eval_f1': 0.9402110199296602, 'eval_accuracy': 0.9853640575619036, 'eval_runtime': 4.0026, 'eval_samples_per_second': 811.969, 'eval_steps_per_second': 5.496, 'epoch': 4.0}\n",
      "{'eval_loss': 0.050601206719875336, 'eval_precision': 0.9348109517601043, 'eval_recall': 0.9480544012089157, 'eval_f1': 0.9413861014723811, 'eval_accuracy': 0.9859163572765487, 'eval_runtime': 4.1988, 'eval_samples_per_second': 774.035, 'eval_steps_per_second': 5.24, 'epoch': 5.0}\n",
      "{'loss': 0.0908, 'grad_norm': 0.5080843567848206, 'learning_rate': 4.4179176711228e-06, 'epoch': 5.32}\n",
      "{'eval_loss': 0.049767933785915375, 'eval_precision': 0.9345742205677059, 'eval_recall': 0.9484321873819418, 'eval_f1': 0.9414522101907842, 'eval_accuracy': 0.9857936240066276, 'eval_runtime': 4.0311, 'eval_samples_per_second': 806.24, 'eval_steps_per_second': 5.458, 'epoch': 6.0}\n",
      "{'eval_loss': 0.050116416066884995, 'eval_precision': 0.9360909260294392, 'eval_recall': 0.9489988666414809, 'eval_f1': 0.9425007034987336, 'eval_accuracy': 0.9858089656653677, 'eval_runtime': 4.0002, 'eval_samples_per_second': 812.463, 'eval_steps_per_second': 5.5, 'epoch': 7.0}\n",
      "{'eval_loss': 0.04985834285616875, 'eval_precision': 0.9359225109434666, 'eval_recall': 0.9490933131847374, 'eval_f1': 0.942461899179367, 'eval_accuracy': 0.9859010156178086, 'eval_runtime': 4.098, 'eval_samples_per_second': 793.074, 'eval_steps_per_second': 5.368, 'epoch': 8.0}\n",
      "{'eval_loss': 0.04994422197341919, 'eval_precision': 0.9353187529083294, 'eval_recall': 0.949187759727994, 'eval_f1': 0.9422022219097174, 'eval_accuracy': 0.9860084072289896, 'eval_runtime': 4.4773, 'eval_samples_per_second': 725.882, 'eval_steps_per_second': 4.914, 'epoch': 9.0}\n",
      "{'eval_loss': 0.04987845569849014, 'eval_precision': 0.9354118194509073, 'eval_recall': 0.9492822062712505, 'eval_f1': 0.9422959733745839, 'eval_accuracy': 0.9860084072289896, 'eval_runtime': 4.0883, 'eval_samples_per_second': 794.955, 'eval_steps_per_second': 5.381, 'epoch': 10.0}\n",
      "{'train_runtime': 192.7104, 'train_samples_per_second': 728.606, 'train_steps_per_second': 4.878, 'train_loss': 0.06250920092805903, 'epoch': 10.0}\n",
      "----------------------------\n",
      "Optimizer: adagrad | Scheduler: linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28966662287712097, 'eval_precision': 0.6083135600667897, 'eval_recall': 0.6537589724216094, 'eval_f1': 0.6302180543542587, 'eval_accuracy': 0.9223251817986561, 'eval_runtime': 3.9089, 'eval_samples_per_second': 831.428, 'eval_steps_per_second': 5.628, 'epoch': 1.0}\n",
      "{'eval_loss': 0.2080087661743164, 'eval_precision': 0.6982238166068773, 'eval_recall': 0.7536834151870041, 'eval_f1': 0.7248943997819868, 'eval_accuracy': 0.9419164800098186, 'eval_runtime': 3.9328, 'eval_samples_per_second': 826.388, 'eval_steps_per_second': 5.594, 'epoch': 2.0}\n",
      "{'eval_loss': 0.1772531121969223, 'eval_precision': 0.7330237448523613, 'eval_recall': 0.7901397808840196, 'eval_f1': 0.7605108858688242, 'eval_accuracy': 0.9500322174833543, 'eval_runtime': 3.9726, 'eval_samples_per_second': 818.104, 'eval_steps_per_second': 5.538, 'epoch': 3.0}\n",
      "{'eval_loss': 0.1612963080406189, 'eval_precision': 0.7531321686959591, 'eval_recall': 0.8061956932376275, 'eval_f1': 0.7787610619469026, 'eval_accuracy': 0.9544966401767359, 'eval_runtime': 3.9299, 'eval_samples_per_second': 826.996, 'eval_steps_per_second': 5.598, 'epoch': 4.0}\n",
      "{'eval_loss': 0.15203481912612915, 'eval_precision': 0.7677028591787655, 'eval_recall': 0.8140347563279184, 'eval_f1': 0.7901902360760945, 'eval_accuracy': 0.9572274554324813, 'eval_runtime': 4.1196, 'eval_samples_per_second': 788.904, 'eval_steps_per_second': 5.34, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory test//adagrad_linear\\checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2928, 'grad_norm': 1.1826488971710205, 'learning_rate': 1.3974358974358975e-05, 'epoch': 5.32}\n",
      "{'eval_loss': 0.1456688940525055, 'eval_precision': 0.777033663719975, 'eval_recall': 0.8218738194182093, 'eval_f1': 0.7988249873777941, 'eval_accuracy': 0.9589610628701175, 'eval_runtime': 4.008, 'eval_samples_per_second': 810.886, 'eval_steps_per_second': 5.489, 'epoch': 6.0}\n",
      "{'eval_loss': 0.1416858285665512, 'eval_precision': 0.7797003210845522, 'eval_recall': 0.82565168114847, 'eval_f1': 0.8020183486238532, 'eval_accuracy': 0.9597895124420852, 'eval_runtime': 3.9955, 'eval_samples_per_second': 813.41, 'eval_steps_per_second': 5.506, 'epoch': 7.0}\n",
      "{'eval_loss': 0.13919326663017273, 'eval_precision': 0.7832393231265109, 'eval_recall': 0.8262183604080091, 'eval_f1': 0.8041549846026567, 'eval_accuracy': 0.9602190788868092, 'eval_runtime': 3.9319, 'eval_samples_per_second': 826.564, 'eval_steps_per_second': 5.595, 'epoch': 8.0}\n",
      "{'eval_loss': 0.13785520195960999, 'eval_precision': 0.7843856197460204, 'eval_recall': 0.828390630902909, 'eval_f1': 0.8057877813504822, 'eval_accuracy': 0.9606333036727931, 'eval_runtime': 3.958, 'eval_samples_per_second': 821.126, 'eval_steps_per_second': 5.558, 'epoch': 9.0}\n",
      "{'eval_loss': 0.137460395693779, 'eval_precision': 0.7845328565042468, 'eval_recall': 0.8287684170759351, 'eval_f1': 0.8060441831626326, 'eval_accuracy': 0.9608174035776749, 'eval_runtime': 3.9684, 'eval_samples_per_second': 818.963, 'eval_steps_per_second': 5.544, 'epoch': 10.0}\n",
      "{'train_runtime': 193.188, 'train_samples_per_second': 726.805, 'train_steps_per_second': 4.866, 'train_loss': 0.23282689033670628, 'epoch': 10.0}\n",
      "----------------------------\n",
      "Optimizer: adagrad | Scheduler: cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28139516711235046, 'eval_precision': 0.618368962787015, 'eval_recall': 0.6638647525500566, 'eval_f1': 0.6403097244363471, 'eval_accuracy': 0.9244883556810163, 'eval_runtime': 4.062, 'eval_samples_per_second': 800.09, 'eval_steps_per_second': 5.416, 'epoch': 1.0}\n",
      "{'eval_loss': 0.19794824719429016, 'eval_precision': 0.7112318205712284, 'eval_recall': 0.7667170381564035, 'eval_f1': 0.7379329151895283, 'eval_accuracy': 0.9448620784879261, 'eval_runtime': 3.9274, 'eval_samples_per_second': 827.524, 'eval_steps_per_second': 5.602, 'epoch': 2.0}\n",
      "{'eval_loss': 0.16779176890850067, 'eval_precision': 0.7429803714461755, 'eval_recall': 0.7972232716282585, 'eval_f1': 0.769146658162103, 'eval_accuracy': 0.9521033414132736, 'eval_runtime': 4.1261, 'eval_samples_per_second': 787.67, 'eval_steps_per_second': 5.332, 'epoch': 3.0}\n",
      "{'eval_loss': 0.15220597386360168, 'eval_precision': 0.7669213004085983, 'eval_recall': 0.8154514544767661, 'eval_f1': 0.7904421862125791, 'eval_accuracy': 0.9572274554324813, 'eval_runtime': 3.9667, 'eval_samples_per_second': 819.315, 'eval_steps_per_second': 5.546, 'epoch': 4.0}\n",
      "{'eval_loss': 0.1437273770570755, 'eval_precision': 0.7800644237652111, 'eval_recall': 0.8233849641103136, 'eval_f1': 0.8011394964160999, 'eval_accuracy': 0.9593752876561014, 'eval_runtime': 4.0751, 'eval_samples_per_second': 797.525, 'eval_steps_per_second': 5.399, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory test//adagrad_cosine\\checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2831, 'grad_norm': 1.14810049533844, 'learning_rate': 1.3392022563188283e-05, 'epoch': 5.32}\n",
      "{'eval_loss': 0.13840194046497345, 'eval_precision': 0.7850366923214606, 'eval_recall': 0.8284850774461655, 'eval_f1': 0.8061759029500966, 'eval_accuracy': 0.9605872786965727, 'eval_runtime': 3.9551, 'eval_samples_per_second': 821.718, 'eval_steps_per_second': 5.562, 'epoch': 6.0}\n",
      "{'eval_loss': 0.13562233746051788, 'eval_precision': 0.7876351290985437, 'eval_recall': 0.8326407253494522, 'eval_f1': 0.8095128781965933, 'eval_accuracy': 0.9614003866098002, 'eval_runtime': 4.1635, 'eval_samples_per_second': 780.601, 'eval_steps_per_second': 5.284, 'epoch': 7.0}\n",
      "{'eval_loss': 0.13425825536251068, 'eval_precision': 0.7899919434249396, 'eval_recall': 0.8334907442387609, 'eval_f1': 0.8111586010386507, 'eval_accuracy': 0.961691878125863, 'eval_runtime': 4.0175, 'eval_samples_per_second': 808.965, 'eval_steps_per_second': 5.476, 'epoch': 8.0}\n",
      "{'eval_loss': 0.13379499316215515, 'eval_precision': 0.7907642742079828, 'eval_recall': 0.8345296562145825, 'eval_f1': 0.8120577152835217, 'eval_accuracy': 0.9619220030069651, 'eval_runtime': 3.9333, 'eval_samples_per_second': 826.275, 'eval_steps_per_second': 5.593, 'epoch': 9.0}\n",
      "{'eval_loss': 0.1337493360042572, 'eval_precision': 0.7909619686800895, 'eval_recall': 0.8348129958443521, 'eval_f1': 0.812296098883426, 'eval_accuracy': 0.9619373446657052, 'eval_runtime': 4.1394, 'eval_samples_per_second': 785.145, 'eval_steps_per_second': 5.315, 'epoch': 10.0}\n",
      "{'train_runtime': 193.5457, 'train_samples_per_second': 725.462, 'train_steps_per_second': 4.857, 'train_loss': 0.22436290497475483, 'epoch': 10.0}\n",
      "----------------------------\n",
      "Optimizer: adagrad | Scheduler: polynomial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at distilbert/distilroberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.29934048652648926, 'eval_precision': 0.5962062000526916, 'eval_recall': 0.6411975821684927, 'eval_f1': 0.6178839590443685, 'eval_accuracy': 0.9192875333681078, 'eval_runtime': 3.9493, 'eval_samples_per_second': 822.921, 'eval_steps_per_second': 5.571, 'epoch': 1.0}\n",
      "{'eval_loss': 0.22242829203605652, 'eval_precision': 0.6837509822753863, 'eval_recall': 0.7396108802417831, 'eval_f1': 0.7105848192005807, 'eval_accuracy': 0.9389401982142309, 'eval_runtime': 3.9487, 'eval_samples_per_second': 823.047, 'eval_steps_per_second': 5.571, 'epoch': 2.0}\n",
      "{'eval_loss': 0.1935511827468872, 'eval_precision': 0.7123072903057225, 'eval_recall': 0.7723838307517945, 'eval_f1': 0.7411300919842312, 'eval_accuracy': 0.9456751864011537, 'eval_runtime': 3.9712, 'eval_samples_per_second': 818.384, 'eval_steps_per_second': 5.54, 'epoch': 3.0}\n",
      "{'eval_loss': 0.18016143143177032, 'eval_precision': 0.7315641968821159, 'eval_recall': 0.7889119758216849, 'eval_f1': 0.7591565936562755, 'eval_accuracy': 0.9494799177687091, 'eval_runtime': 3.9534, 'eval_samples_per_second': 822.077, 'eval_steps_per_second': 5.565, 'epoch': 4.0}\n",
      "{'eval_loss': 0.17293959856033325, 'eval_precision': 0.7388282899366643, 'eval_recall': 0.7932565168114847, 'eval_f1': 0.7650756057569684, 'eval_accuracy': 0.9511214752539044, 'eval_runtime': 4.1786, 'eval_samples_per_second': 777.776, 'eval_steps_per_second': 5.265, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory test//adagrad_polynomial\\checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3092, 'grad_norm': 1.234157919883728, 'learning_rate': 6.58772554605888e-06, 'epoch': 5.32}\n",
      "{'eval_loss': 0.1688489019870758, 'eval_precision': 0.7424349049964813, 'eval_recall': 0.7971288250850019, 'eval_f1': 0.7688103479686645, 'eval_accuracy': 0.952041974778313, 'eval_runtime': 3.9689, 'eval_samples_per_second': 818.868, 'eval_steps_per_second': 5.543, 'epoch': 6.0}\n",
      "{'eval_loss': 0.1669256091117859, 'eval_precision': 0.7442126573365021, 'eval_recall': 0.7985455232338496, 'eval_f1': 0.77042234270354, 'eval_accuracy': 0.9525329078579976, 'eval_runtime': 4.0167, 'eval_samples_per_second': 809.13, 'eval_steps_per_second': 5.477, 'epoch': 7.0}\n",
      "{'eval_loss': 0.16586633026599884, 'eval_precision': 0.746079295154185, 'eval_recall': 0.7997733282961843, 'eval_f1': 0.7719938007110949, 'eval_accuracy': 0.9528243993740603, 'eval_runtime': 4.0116, 'eval_samples_per_second': 810.144, 'eval_steps_per_second': 5.484, 'epoch': 8.0}\n",
      "{'eval_loss': 0.16548708081245422, 'eval_precision': 0.746717193971975, 'eval_recall': 0.8002455610124669, 'eval_f1': 0.7725552769546387, 'eval_accuracy': 0.9529931576202019, 'eval_runtime': 3.9811, 'eval_samples_per_second': 816.355, 'eval_steps_per_second': 5.526, 'epoch': 9.0}\n",
      "{'eval_loss': 0.16541124880313873, 'eval_precision': 0.747025121198766, 'eval_recall': 0.80043445409898, 'eval_f1': 0.7728080973874983, 'eval_accuracy': 0.9530238409376822, 'eval_runtime': 4.0912, 'eval_samples_per_second': 794.38, 'eval_steps_per_second': 5.377, 'epoch': 10.0}\n",
      "{'train_runtime': 193.0756, 'train_samples_per_second': 727.228, 'train_steps_per_second': 4.869, 'train_loss': 0.25650560906592834, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "df = pii.train(\n",
    "    output_dir = \"test/\",\n",
    "    optimizers = optimizers,\n",
    "    schedulers = schedulers,\n",
    "    tokenizer_path = model_path,\n",
    "    model_path = model_path,\n",
    "    strategy = \"epoch\",\n",
    "    epochs = 10,\n",
    "    batch_size = 150,\n",
    "    result_csv = \"test.csv\",\n",
    "    device = \"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melanoma identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "skincancer_model_path = \"apple/mobilevit-small\"\n",
    "\n",
    "skin_cancer = SkinCancer()\n",
    "skin_cancer.load_image_processor(skincancer_model_path)\n",
    "skin_cancer.prepare_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {\n",
    "    \"adamw\": (torch.optim.AdamW, {\"lr\": 2e-4}),\n",
    "    \"rmsprop\": (torch.optim.RMSprop, {\"lr\": 2e-4, \"momentum\": 0}),\n",
    "    \"adagrad\": (torch.optim.Adagrad, {\"lr\": 3e-5}),\n",
    "}\n",
    "\n",
    "schedulers = {\n",
    "    \"linear\": {\"num_warmup_steps\": 0},\n",
    "    \"cosine\": {\"num_warmup_steps\": 0},\n",
    "    \"polynomial\": {\"num_warmup_steps\": 0, \"power\": 2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "Optimizer: adamw | Scheduler: linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of MobileViTForImageClassification were not initialized from the model checkpoint at apple/mobilevit-small and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 640]) in the checkpoint and torch.Size([7, 640]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "MobileViTForImageClassification.forward() got an unexpected keyword argument 'age'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mskin_cancer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresult_csv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschedulers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mschedulers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage_processor_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskincancer_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mskincancer_model_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m24\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepoch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bwa\\Documents\\UW\\515_project\\project\\datasets.py:659\u001b[0m, in \u001b[0;36mSkinCancer.train\u001b[1;34m(self, output_dir, optimizers, schedulers, image_processor_path, model_path, strategy, epochs, batch_size, result_csv, device)\u001b[0m\n\u001b[0;32m    646\u001b[0m t0 \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m    648\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[0;32m    650\u001b[0m     args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    656\u001b[0m     optimizers \u001b[38;5;241m=\u001b[39m (_optimizer, _scheduler)\n\u001b[0;32m    657\u001b[0m )\n\u001b[1;32m--> 659\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    661\u001b[0m predictions, labels, _ \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    663\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric\u001b[38;5;241m.\u001b[39mcompute(\n\u001b[0;32m    664\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    665\u001b[0m     references \u001b[38;5;241m=\u001b[39m labels\n\u001b[0;32m    666\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Bwa\\anaconda3\\envs\\515_project_gpu\\lib\\site-packages\\transformers\\trainer.py:1624\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1622\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1623\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1624\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1626\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1627\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1628\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1629\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bwa\\anaconda3\\envs\\515_project_gpu\\lib\\site-packages\\transformers\\trainer.py:1961\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1958\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1961\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1963\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1964\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1965\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1966\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1967\u001b[0m ):\n\u001b[0;32m   1968\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1969\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\Users\\Bwa\\anaconda3\\envs\\515_project_gpu\\lib\\site-packages\\transformers\\trainer.py:2902\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2901\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2902\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2905\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bwa\\anaconda3\\envs\\515_project_gpu\\lib\\site-packages\\transformers\\trainer.py:2925\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2923\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2924\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 2925\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m   2926\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   2927\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   2928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Bwa\\anaconda3\\envs\\515_project_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Bwa\\anaconda3\\envs\\515_project_gpu\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: MobileViTForImageClassification.forward() got an unexpected keyword argument 'age'"
     ]
    }
   ],
   "source": [
    "df = skin_cancer.train(\n",
    "    output_dir = \"test/\",\n",
    "    result_csv = \"test.csv\",\n",
    "    optimizers = optimizers,\n",
    "    schedulers = schedulers,\n",
    "    image_processor_path= skincancer_model_path,\n",
    "    model_path = skincancer_model_path,\n",
    "    epochs = 1,\n",
    "    batch_size = 24,\n",
    "    strategy=\"epoch\",\n",
    "    device = \"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = load_dataset(path = \"ai4privacy/pii-masking-200k\", data_files = \"english_pii_43k.jsonl\")\n",
    "dataset = load_dataset(path = \"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"marmal88/skin_cancer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'image_id', 'lesion_id', 'dx', 'dx_type', 'age', 'sex', 'localization'],\n",
       "        num_rows: 9577\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'image_id', 'lesion_id', 'dx', 'dx_type', 'age', 'sex', 'localization'],\n",
       "        num_rows: 2492\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'image_id', 'lesion_id', 'dx', 'dx_type', 'age', 'sex', 'localization'],\n",
       "        num_rows: 1285\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'actinic_keratoses'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][0][\"dx\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD Algorithms: \n",
    "- \"adamw_torch\"\n",
    "- \"adagrad\"\n",
    "- \"rmsprop\"\n",
    "\n",
    "\n",
    "LR Schedulers:\n",
    "\n",
    "- \"cosine\"\n",
    "- \"inverse_sqrt\"\n",
    "\n",
    "inverse_sqrt = lambda step: 1/math.sqrt(step, 100)\n",
    "\n",
    "scheduler = LambdaLR(optimizer, lr_lambda = inverse_sqrt)\n",
    "\n",
    "\n",
    "- \"reduce_lr_on_plateau\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "515_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
